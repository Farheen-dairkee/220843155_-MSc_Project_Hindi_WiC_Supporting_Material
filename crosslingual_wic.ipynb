{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-_8E_tKxvLV"
      },
      "source": [
        "## Choose Devise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-08T19:56:54.824112Z",
          "iopub.status.busy": "2023-08-08T19:56:54.822901Z",
          "iopub.status.idle": "2023-08-08T19:56:55.843774Z",
          "shell.execute_reply": "2023-08-08T19:56:55.842549Z",
          "shell.execute_reply.started": "2023-08-08T19:56:54.824063Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXE-_ZQaxvLX",
        "outputId": "45322652-88fe-466f-b283-fc33d46ecbe6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: NVIDIA A100-SXM4-40GB\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():\n",
        "\n",
        "    # Tell PyTorch to use the GPU.\n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQvdqslPxvLa"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-08T19:56:55.955312Z",
          "iopub.status.busy": "2023-08-08T19:56:55.954795Z",
          "iopub.status.idle": "2023-08-08T19:57:01.866933Z",
          "shell.execute_reply": "2023-08-08T19:57:01.865054Z",
          "shell.execute_reply.started": "2023-08-08T19:56:55.955285Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kz5vbw7oxvLa",
        "outputId": "80b30641-32fc-49d8-a4da-07c263b9e28b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-transformers\n",
            "  Downloading pytorch_transformers-1.2.0-py3-none-any.whl (176 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/176.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m143.4/176.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.4/176.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-transformers) (2.0.1+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pytorch-transformers) (1.23.5)\n",
            "Collecting boto3 (from pytorch-transformers)\n",
            "  Downloading boto3-1.28.32-py3-none-any.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pytorch-transformers) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pytorch-transformers) (4.66.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from pytorch-transformers) (2023.6.3)\n",
            "Collecting sentencepiece (from pytorch-transformers)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sacremoses (from pytorch-transformers)\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->pytorch-transformers) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->pytorch-transformers) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->pytorch-transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->pytorch-transformers) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->pytorch-transformers) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->pytorch-transformers) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.0.0->pytorch-transformers) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.0.0->pytorch-transformers) (16.0.6)\n",
            "Collecting botocore<1.32.0,>=1.31.32 (from boto3->pytorch-transformers)\n",
            "  Downloading botocore-1.31.32-py3-none-any.whl (11.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3->pytorch-transformers)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0 (from boto3->pytorch-transformers)\n",
            "  Downloading s3transfer-0.6.2-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-transformers) (2023.7.22)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sacremoses->pytorch-transformers) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses->pytorch-transformers) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses->pytorch-transformers) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.32.0,>=1.31.32->boto3->pytorch-transformers) (2.8.2)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests->pytorch-transformers)\n",
            "  Downloading urllib3-1.26.16-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.1/143.1 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.0->pytorch-transformers) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.0.0->pytorch-transformers) (1.3.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895240 sha256=ff279d9868c22a08f0749cbc60c5df5cf201c7f8d7bb93dcd390b3fb1988ce13\n",
            "  Stored in directory: /root/.cache/pip/wheels/00/24/97/a2ea5324f36bc626e1ea0267f33db6aa80d157ee977e9e42fb\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, urllib3, sacremoses, jmespath, botocore, s3transfer, boto3, pytorch-transformers\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.4\n",
            "    Uninstalling urllib3-2.0.4:\n",
            "      Successfully uninstalled urllib3-2.0.4\n",
            "Successfully installed boto3-1.28.32 botocore-1.31.32 jmespath-1.0.1 pytorch-transformers-1.2.0 s3transfer-0.6.2 sacremoses-0.0.53 sentencepiece-0.1.99 urllib3-1.26.16\n"
          ]
        }
      ],
      "source": [
        "pip install pytorch-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-08T19:57:01.870153Z",
          "iopub.status.busy": "2023-08-08T19:57:01.869410Z",
          "iopub.status.idle": "2023-08-08T19:57:05.815084Z",
          "shell.execute_reply": "2023-08-08T19:57:05.813821Z",
          "shell.execute_reply.started": "2023-08-08T19:57:01.870074Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVsXSp8CxvLa",
        "outputId": "70c134e3-a5f3-4d78-988c-97ca53040be6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.32.0-py3-none-any.whl (7.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.2 tokenizers-0.13.3 transformers-4.32.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-08T19:57:05.816849Z",
          "iopub.status.busy": "2023-08-08T19:57:05.816558Z",
          "iopub.status.idle": "2023-08-08T19:57:06.935946Z",
          "shell.execute_reply": "2023-08-08T19:57:06.934940Z",
          "shell.execute_reply.started": "2023-08-08T19:57:05.816820Z"
        },
        "id": "1UDt2wfWxvLb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "import string\n",
        "import copy\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from sklearn.metrics import classification_report\n",
        "from pytorch_transformers import *\n",
        "import numpy as np\n",
        "import json\n",
        "import collections\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-08T19:57:06.938854Z",
          "iopub.status.busy": "2023-08-08T19:57:06.938259Z",
          "iopub.status.idle": "2023-08-08T19:57:06.943425Z",
          "shell.execute_reply": "2023-08-08T19:57:06.942047Z",
          "shell.execute_reply.started": "2023-08-08T19:57:06.938817Z"
        },
        "id": "6S9Kji_LxvLb"
      },
      "outputs": [],
      "source": [
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IpHrvLLxvLc"
      },
      "source": [
        "## Import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-08T20:18:02.281922Z",
          "iopub.status.busy": "2023-08-08T20:18:02.281566Z",
          "iopub.status.idle": "2023-08-08T20:18:02.347841Z",
          "shell.execute_reply": "2023-08-08T20:18:02.346444Z",
          "shell.execute_reply.started": "2023-08-08T20:18:02.281895Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDFjheBPxvLc",
        "outputId": "4614d8b9-b3e8-45e1-f735-3a798f77f1bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5428\n"
          ]
        }
      ],
      "source": [
        "#load_data basically reads in data --> takes in everything from jsonl files\n",
        "def load_data(filename):\n",
        "    data = []\n",
        "    # read in each line and add it to list\n",
        "    with open(filename, mode = \"r\") as file:\n",
        "        for line in file:\n",
        "            data.append(json.loads(line))\n",
        "    return data\n",
        "\n",
        "\n",
        "train_json_objs = load_data(\"train.jsonl\")\n",
        "\n",
        "sentences1=[]\n",
        "sentences2=[]\n",
        "words=[]\n",
        "labels=[]\n",
        "for i in range(0,len(train_json_objs)):\n",
        "    sentences1.append(train_json_objs[i]['sentence1'])\n",
        "    sentences2.append(train_json_objs[i]['sentence2'])\n",
        "    words.append(train_json_objs[i]['word'])\n",
        "    labels.append(train_json_objs[i]['label'])\n",
        "\n",
        "print(len(sentences1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "po_CDYPGxvLc"
      },
      "source": [
        "## Import Model & Model Tokenizer | Model Definition"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### List of models present in the experiment:\n",
        "The below models specified were used for the purpose to understand how the models perform when trained and tested on the Hindi Language:\n",
        "\n",
        "* bert-base-multilingual-cased\n",
        "\n",
        "* xlm-roberta-base\n",
        "\n",
        "Please remove the # character to run the chosen model."
      ],
      "metadata": {
        "id": "KEGqvaqny1A7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-08T19:57:09.213334Z",
          "iopub.status.busy": "2023-08-08T19:57:09.212814Z",
          "iopub.status.idle": "2023-08-08T19:57:12.949978Z",
          "shell.execute_reply": "2023-08-08T19:57:12.949137Z",
          "shell.execute_reply.started": "2023-08-08T19:57:09.213292Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130,
          "referenced_widgets": [
            "1285ba33c84e433ebb7bad7c65a7786b",
            "18eb570aedd54c25b639ae20ed6a7dd4",
            "63a2b01df7de467982dddb133172ae00",
            "45515774e49e4c31bffffbacbe50da7e",
            "541a6ef8a939449394bb44b502a3e565",
            "f75049eac5534077a819d7ed2cdcf941",
            "da97aa5771d94756b154fb4faea61c1a",
            "fafd13f82f0c4aa2934b266915721516",
            "c94d9f4f0c4a458eb998d1a44687a334",
            "b94c72ce11d342c4b2857b60c87b6d54",
            "11d25617b73e458fb203e270eaab250f",
            "4b3b8d95f17642c1bed815e97f0e14f8",
            "22c1cc728c2b41d4898933121c9f2fe8",
            "cb98d29d981148a3b5c494fbee3eb92a",
            "5e5601f8691249bd9480c456f9e354ab",
            "b5bc9cf4a1a34412b318fe9084d0a779",
            "d642308d57f443828c7de94a8e73a126",
            "0338d6144d764f198ac61ee8c9e9bdf9",
            "481a6d719ee74937bc8fe6800194a12f",
            "67635a8a2ea2490b875c775a15850707",
            "616def7743554c3c893c45d66c9f20f4",
            "d8b3f21a5d3a4acf855e46836ca48751",
            "8e8b67e3684c437c9d2e6e0a4b2a8ab5",
            "e064157216534f3bab41eb8d7e6b82eb",
            "d162fb82de114ddaa71c051aa8fef1ed",
            "f4932b80fe724bda8d493c0eba9d8a28",
            "db49a123f6764db1a89db7973e48c40e",
            "ee41a4d3be2a4b07914add6d0c70e562",
            "e335c757e5454cab8f68ccfc722bbfee",
            "e971ac16ad4d4bc0b8eda6c25c9a04a2",
            "a05021b7ad3748ca852d7900e19e328e",
            "baee3fcb5d504e209bb9b28733a69554",
            "4507b375f0934e6da8fe176ec4c8661e"
          ]
        },
        "id": "SIUsByIvxvLd",
        "outputId": "b10cb0b6-8372-4ee4-c2c8-b0b1a4633edf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "xlm-roberta-base\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1285ba33c84e433ebb7bad7c65a7786b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)tencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4b3b8d95f17642c1bed815e97f0e14f8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8e8b67e3684c437c9d2e6e0a4b2a8ab5"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n",
        "model_name='xlm-roberta-base'\n",
        "#model_name='bert-base-multilingual-cased'\n",
        "print(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-08T19:57:30.293104Z",
          "iopub.status.busy": "2023-08-08T19:57:30.291645Z",
          "iopub.status.idle": "2023-08-08T19:57:48.297454Z",
          "shell.execute_reply": "2023-08-08T19:57:48.296359Z",
          "shell.execute_reply.started": "2023-08-08T19:57:30.293072Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867,
          "referenced_widgets": [
            "7ee4abd09365479db3b86cc2106de9e6",
            "e9109ee6f7a8414d8450169413e3f281",
            "0a3f8f8c15b6494b8ddbcdd4fe996ebe",
            "52686a3a893b47c4b95485e9f45dc685",
            "a10959b28e7642588741b0e9f344ecb2",
            "9d7222be685741328e7fd332fb615b15",
            "90c6de5ce888439d90ddf9ab740d81e0",
            "f163fdef65d24fb7bcec80d6bde4b669",
            "2f055de872e14133b294c7c36a2a5b77",
            "6d4c66d9847e421c80b10cfffe940aec",
            "39d7b26d0e92491a9600ae42a31cdf68"
          ]
        },
        "id": "uR9uUiDnxvLd",
        "outputId": "16c63c4f-e367-4417-fccb-1d99dac41d74"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7ee4abd09365479db3b86cc2106de9e6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XLMRobertaForSequenceClassification(\n",
              "  (roberta): XLMRobertaModel(\n",
              "    (embeddings): XLMRobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): XLMRobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x XLMRobertaLayer(\n",
              "          (attention): XLMRobertaAttention(\n",
              "            (self): XLMRobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): XLMRobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): XLMRobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): XLMRobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): XLMRobertaClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "    # output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = True, # Whether the model returns all hidden-states.\n",
        ")\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwGwN1I5xvLd"
      },
      "source": [
        "## Create Train Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLOCkoHwxvLe"
      },
      "source": [
        "The below functions will find the range of indexes of the target words from the two context sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-08T19:57:50.803281Z",
          "iopub.status.busy": "2023-08-08T19:57:50.802882Z",
          "iopub.status.idle": "2023-08-08T19:57:50.810325Z",
          "shell.execute_reply": "2023-08-08T19:57:50.809203Z",
          "shell.execute_reply.started": "2023-08-08T19:57:50.803256Z"
        },
        "id": "W3uceusJxvLe"
      },
      "outputs": [],
      "source": [
        "def find_indexes_before(list1, list2):\n",
        "    index = 0\n",
        "    while index <= len(list1) - len(list2):\n",
        "        if list1[index:index + len(list2)] == list2:\n",
        "            return list(range(index, index + len(list2)))\n",
        "        index += 1\n",
        "    return []\n",
        "\n",
        "def find_indexes_after(list1, before_length,list2):\n",
        "    index = 0\n",
        "    while index <= len(list1) - len(list2):\n",
        "        if list1[index:index + len(list2)] == list2:\n",
        "            #print(index)\n",
        "            return list(range(index +before_length, index +before_length +  len(list2)))\n",
        "        index += 1\n",
        "    return []"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGHgXfkT0Jit",
        "outputId": "6628834a-4ecb-40c7-fac2-1557155f4751"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "e_JzznpAxvLf"
      },
      "outputs": [],
      "source": [
        "# This step is done to preprocess th target words in the English WiC dataset\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ce5vtX_5xvLe"
      },
      "source": [
        "The below function creates the dataset in the required format that is it contains a dictionary of lists with:\n",
        "1. Input IDs -  sequence of integer tokens that represent the input text. Each token in the text is mapped to a unique integer ID based on a tokenizer. BERT uses a fixed-size vocabulary, and each token in the text is converted to its corresponding ID from the vocabulary.\n",
        "\n",
        "2. Attention mask - binary mask tensor that indicates which tokens in the input should be attended to (receive attention) and which tokens should be ignored. It is used to handle variable-length input sequences. The mask has the same length as the input sequence and contains 0s and 1s\n",
        "\n",
        "3. Target Word Location in sentence 1 - used to extract embeddings of target word from sentence 1\n",
        "\n",
        "4. Target Word Location in sentence 2 - used to extract embeddings of target word from sentence 2\n",
        "\n",
        "5. Labels\n",
        "\n",
        "** Note: Please remove the # character on the below lines if specifically XLM-RoBERTa model is used:\n",
        "\n",
        "```\n",
        "sentence = f\"<s> {sentences1[i]}</s><s>{sentences2[i]}</s>\"\n",
        "s_token_index = tokenizer.convert_tokens_to_ids('</s>')\n",
        "sep_occurrences = [index for index, token_id in enumerate(input_ids) if token_id == s_token_index]\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-08T20:27:12.149447Z",
          "iopub.status.busy": "2023-08-08T20:27:12.149036Z",
          "iopub.status.idle": "2023-08-08T20:27:12.164128Z",
          "shell.execute_reply": "2023-08-08T20:27:12.162494Z",
          "shell.execute_reply.started": "2023-08-08T20:27:12.149447Z"
        },
        "id": "Do3CBHW3xvLf"
      },
      "outputs": [],
      "source": [
        "\n",
        "def create_data_set(sentences1,sentences2,target_word,labels):\n",
        "    wic_padded=[]\n",
        "    missed=[]\n",
        "    for i in range(0,len(sentences1)):\n",
        "        lemmatized_tokens=[]\n",
        "        tokens = word_tokenize(sentences1[i])\n",
        "        for t1 in tokens:\n",
        "            lemma = lemmatizer.lemmatize(t1)\n",
        "            lemmatized_tokens.append(lemma.lower())\n",
        "        lemmatized_sentence1 = ' '.join(lemmatized_tokens)\n",
        "\n",
        "        lemmatized_tokens=[]\n",
        "        tokens = word_tokenize(sentences2[i])\n",
        "        for t1 in tokens:\n",
        "            lemma = lemmatizer.lemmatize(t1)\n",
        "            lemmatized_tokens.append(lemma.lower())\n",
        "        lemmatized_sentence2 = ' '.join(lemmatized_tokens)\n",
        "\n",
        "        #print(words[i])\n",
        "        #sentence = f\"[CLS] {lemmatized_sentence1} [SEP] {lemmatized_sentence2} [SEP]\"\n",
        "        sentence = f\"<s> {sentences1[i]}</s><s>{sentences2[i]}</s>\"\n",
        "        #print(sentence)\n",
        "        tokens=tokenizer(sentence, add_special_tokens=False,pad_to_max_length=True,\n",
        "                  truncation=True,max_length=512)\n",
        "        input_ids = tokens[\"input_ids\"]\n",
        "        attention_mask = tokens[\"attention_mask\"]\n",
        "        #print(input_ids)\n",
        "        target_word=words[i]\n",
        "        target_token = tokenizer.encode(target_word)\n",
        "        target_token=target_token[1:-1]\n",
        "\n",
        "        #For XLM-RoBERTa\n",
        "        s_token_index = tokenizer.convert_tokens_to_ids('</s>')\n",
        "        sep_occurrences = [index for index, token_id in enumerate(input_ids) if token_id == s_token_index]\n",
        "\n",
        "        #ANY OTHER MODEL\n",
        "        #sep_occurrences = [index for index, token_id in enumerate(input_ids) if token_id == tokenizer.sep_token_id]\n",
        "\n",
        "        if len(sep_occurrences)!=0:\n",
        "            sep_index = sep_occurrences[0]\n",
        "\n",
        "            tokens_before_sep = input_ids[:sep_index]\n",
        "            tokens_after_sep = input_ids[sep_index + 1:]\n",
        "\n",
        "            is_present1= str(target_token).replace(\"[\",\"\").replace(\"]\",\"\") in str(tokens_before_sep)\n",
        "            is_present2= str(target_token).replace(\"[\",\"\").replace(\"]\",\"\") in str(tokens_after_sep)\n",
        "\n",
        "            if is_present1!=False and is_present2!=False:\n",
        "                target_word_ids_before_sep = find_indexes_before(tokens_before_sep,target_token)\n",
        "                target_word_ids_after_sep = find_indexes_after(tokens_after_sep,len(tokens_before_sep)-1,target_token)\n",
        "                if labels[i]==False:\n",
        "                    label=0\n",
        "                else:\n",
        "                    label=1\n",
        "\n",
        "                mask_tensor_sent1 = torch.zeros_like(torch.tensor(input_ids))\n",
        "                mask_tensor_sent1[target_word_ids_before_sep] = 1\n",
        "                mask_tensor_sent2 = torch.zeros_like(torch.tensor(input_ids))\n",
        "                mask_tensor_sent2[target_word_ids_after_sep] = 1\n",
        "                sample_data = {\n",
        "                                \"input_ids\": torch.tensor(input_ids),\n",
        "                                \"attention_mask\": torch.tensor(attention_mask),\n",
        "                                \"word1_locs\": mask_tensor_sent1,\n",
        "                                \"word2_locs\": mask_tensor_sent2,\n",
        "                                \"labels\": torch.tensor(label),\n",
        "                                \"sentence\": sentence,\n",
        "                                \"target_word\":words[i]\n",
        "                            }\n",
        "\n",
        "                # Append the data for the current sample to the list\n",
        "                wic_padded.append(sample_data)\n",
        "            else:missed.append([sentence, words[i]])\n",
        "        else:missed.append([sentence, words[i]])\n",
        "    return wic_padded,missed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-08T20:27:16.466505Z",
          "iopub.status.busy": "2023-08-08T20:27:16.465977Z",
          "iopub.status.idle": "2023-08-08T20:27:17.530258Z",
          "shell.execute_reply": "2023-08-08T20:27:17.529156Z",
          "shell.execute_reply.started": "2023-08-08T20:27:16.466505Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSzmHbKixvLg",
        "outputId": "fac1b469-9e45-4926-b6e4-6422fefd84f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "#create training dataset\n",
        "\n",
        "wic_train_set,l1 = create_data_set(sentences1,sentences2,words,labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-08T20:27:17.533012Z",
          "iopub.status.busy": "2023-08-08T20:27:17.532689Z",
          "iopub.status.idle": "2023-08-08T20:27:17.539242Z",
          "shell.execute_reply": "2023-08-08T20:27:17.537691Z",
          "shell.execute_reply.started": "2023-08-08T20:27:17.532926Z"
        },
        "id": "z_TWiLH4xvLg"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-08T20:27:18.061759Z",
          "iopub.status.busy": "2023-08-08T20:27:18.060640Z",
          "iopub.status.idle": "2023-08-08T20:27:18.069233Z",
          "shell.execute_reply": "2023-08-08T20:27:18.068026Z",
          "shell.execute_reply.started": "2023-08-08T20:27:18.061728Z"
        },
        "id": "pWFdCOVSxvLg"
      },
      "outputs": [],
      "source": [
        "train_labels=[]\n",
        "for i in wic_train_set:\n",
        "    x=i[\"labels\"].item()\n",
        "    train_labels.append(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-08T20:27:21.716954Z",
          "iopub.status.busy": "2023-08-08T20:27:21.715796Z",
          "iopub.status.idle": "2023-08-08T20:27:21.734414Z",
          "shell.execute_reply": "2023-08-08T20:27:21.733207Z",
          "shell.execute_reply.started": "2023-08-08T20:27:21.716907Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAA1fTHZxvLg",
        "outputId": "97eecc07-dfdd-4e5a-bae6-049ffe90f8cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentence:  <s> Do you want to come over to my place later?</s><s>A political system with no place for the less prominent groups.</s>\n",
            "target_word:  place\n",
            "word1 location:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n",
            "word2 location:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n"
          ]
        }
      ],
      "source": [
        "for i in wic_train_set:\n",
        "    x=i[\"word1_locs\"]\n",
        "    y=i[\"word2_locs\"]\n",
        "    print(\"sentence: \",i[\"sentence\"])\n",
        "    print(\"target_word: \",i[\"target_word\"])\n",
        "    print(\"word1 location: \",x)\n",
        "    print(\"word2 location: \",y)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-08T20:27:51.890754Z",
          "iopub.status.busy": "2023-08-08T20:27:51.889775Z",
          "iopub.status.idle": "2023-08-08T20:27:51.902424Z",
          "shell.execute_reply": "2023-08-08T20:27:51.901369Z",
          "shell.execute_reply.started": "2023-08-08T20:27:51.890726Z"
        },
        "id": "ZkgDajX2xvLh"
      },
      "outputs": [],
      "source": [
        "train_data = TensorDataset(\n",
        "    torch.stack([sample[\"input_ids\"] for sample in wic_train_set]),\n",
        "    torch.stack([sample[\"attention_mask\"] for sample in wic_train_set]),\n",
        "    torch.stack([sample[\"word1_locs\"] for sample in wic_train_set]),\n",
        "    torch.stack([sample[\"word2_locs\"] for sample in wic_train_set]),\n",
        "    torch.stack([sample[\"labels\"] for sample in wic_train_set])\n",
        ")\n",
        "\n",
        "# Create a sampler and loader\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_D5LUQD9xvLh"
      },
      "source": [
        "## Create Validation Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-08T20:27:56.007113Z",
          "iopub.status.busy": "2023-08-08T20:27:56.006515Z",
          "iopub.status.idle": "2023-08-08T20:27:56.038356Z",
          "shell.execute_reply": "2023-08-08T20:27:56.037741Z",
          "shell.execute_reply.started": "2023-08-08T20:27:56.007113Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMG7YVi4xvLh",
        "outputId": "7309ca76-7989-4c12-d291-059970e2dd17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "638\n"
          ]
        }
      ],
      "source": [
        "#load_data basically reads in data --> takes in everything from jsonl files\n",
        "def load_data(filename):\n",
        "    data = []\n",
        "    # read in each line and add it to list\n",
        "    with open(filename, mode = \"r\") as file:\n",
        "        for line in file:\n",
        "            data.append(json.loads(line))\n",
        "    return data\n",
        "\n",
        "\n",
        "train_json_objs = load_data(\"val.jsonl\")\n",
        "\n",
        "sentences1=[]\n",
        "sentences2=[]\n",
        "words=[]\n",
        "labels=[]\n",
        "for i in range(0,len(train_json_objs)):\n",
        "    sentences1.append(train_json_objs[i]['sentence1'])\n",
        "    sentences2.append(train_json_objs[i]['sentence2'])\n",
        "    words.append(train_json_objs[i]['word'])\n",
        "    labels.append(train_json_objs[i]['label'])\n",
        "\n",
        "print(len(sentences1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-08T20:31:02.464828Z",
          "iopub.status.busy": "2023-08-08T20:31:02.463563Z",
          "iopub.status.idle": "2023-08-08T20:31:03.396949Z",
          "shell.execute_reply": "2023-08-08T20:31:03.395616Z",
          "shell.execute_reply.started": "2023-08-08T20:31:02.464828Z"
        },
        "id": "RtqRYpR7xvLh"
      },
      "outputs": [],
      "source": [
        "#create validation dataset\n",
        "\n",
        "wic_val_set,l1 = create_data_set(sentences1,sentences2,words,labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-08T20:31:04.845177Z",
          "iopub.status.busy": "2023-08-08T20:31:04.844783Z",
          "iopub.status.idle": "2023-08-08T20:31:04.857050Z",
          "shell.execute_reply": "2023-08-08T20:31:04.855929Z",
          "shell.execute_reply.started": "2023-08-08T20:31:04.845149Z"
        },
        "id": "VKaetke1xvLi"
      },
      "outputs": [],
      "source": [
        "\n",
        "val_data = TensorDataset(\n",
        "    torch.stack([sample[\"input_ids\"] for sample in wic_val_set]),\n",
        "    torch.stack([sample[\"attention_mask\"] for sample in wic_val_set]),\n",
        "    torch.stack([sample[\"word1_locs\"] for sample in wic_val_set]),\n",
        "    torch.stack([sample[\"word2_locs\"] for sample in wic_val_set]),\n",
        "    torch.stack([sample[\"labels\"] for sample in wic_val_set])\n",
        ")\n",
        "\n",
        "# Create a sampler and loader\n",
        "val_sampler = RandomSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0g-xdIHRxvLi"
      },
      "source": [
        "## Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-08T20:31:08.986230Z",
          "iopub.status.busy": "2023-08-08T20:31:08.985682Z",
          "iopub.status.idle": "2023-08-08T20:31:08.998865Z",
          "shell.execute_reply": "2023-08-08T20:31:08.997550Z",
          "shell.execute_reply.started": "2023-08-08T20:31:08.986097Z"
        },
        "id": "XsJAELpmxvLi"
      },
      "outputs": [],
      "source": [
        "\n",
        "class WiC_Head(torch.nn.Module):\n",
        "    def __init__(self, model_used,weights,embedding_size=768):\n",
        "        super(WiC_Head, self).__init__()\n",
        "        self.model=model_used\n",
        "        self.embedding_size = embedding_size\n",
        "        self.linear_diff = torch.nn.Linear(embedding_size, 100, bias=True)\n",
        "        self.linear_seperator = torch.nn.Linear(100, 2, bias=True)\n",
        "        self.loss = torch.nn.CrossEntropyLoss(weight=weights)\n",
        "        self.activation = torch.nn.ReLU()\n",
        "        self.softmax = torch.nn.Softmax()\n",
        "\n",
        "        self.to(device)\n",
        "        self.linear_diff.to(device)\n",
        "        self.loss.to(device)\n",
        "        self.linear_seperator.to(device)\n",
        "        self.activation.to(device)\n",
        "        self.softmax.to(device)\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None, word1_locs=None, word2_locs=None, labels=None):\n",
        "        batch_size = input_ids.shape[0]\n",
        "        input_ids_tensor = input_ids.to(device)\n",
        "        attention_mask_tensor = attention_mask.to(device)\n",
        "        word1_locs = word1_locs.to(device)\n",
        "        word1_locs=word1_locs.unsqueeze(1)\n",
        "\n",
        "        word2_locs = word2_locs.to(device)\n",
        "        word2_locs=word2_locs.unsqueeze(1)\n",
        "\n",
        "        outputs=model(input_ids_tensor,attention_mask_tensor)\n",
        "\n",
        "        token_embeddings=outputs.hidden_states[-1]\n",
        "\n",
        "        token_embeddings = torch.squeeze(token_embeddings, dim=0)\n",
        "\n",
        "        word1_embs=torch.matmul(word1_locs.float(),token_embeddings.float()).view(batch_size, self.embedding_size)\n",
        "\n",
        "        word2_embs=torch.matmul(word2_locs.float(),token_embeddings.float()).view(batch_size, self.embedding_size)\n",
        "\n",
        "        diff = word1_embs - word2_embs\n",
        "\n",
        "        layer1_results = self.activation(self.linear_diff(diff))\n",
        "        logits = self.softmax(self.linear_seperator(layer1_results))\n",
        "        if labels is not None:\n",
        "            loss = self.loss(logits.view(-1, 2).to(device), labels.view(-1).to(device))\n",
        "            outputs = (loss, logits)\n",
        "        return outputs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3R6D22LSxvLi"
      },
      "source": [
        "We need to ensure that both classes are assigned weights accordingly in case any class in our dataset over represented"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-08T20:31:11.191322Z",
          "iopub.status.busy": "2023-08-08T20:31:11.190830Z",
          "iopub.status.idle": "2023-08-08T20:31:11.217384Z",
          "shell.execute_reply": "2023-08-08T20:31:11.216066Z",
          "shell.execute_reply.started": "2023-08-08T20:31:11.191286Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBIASO40xvLi",
        "outputId": "eefa3603-229b-4bcf-8ef9-b84db5ad1938"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.07196198 0.93709199]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "#compute the class weights\n",
        "class_wts = compute_class_weight('balanced', classes=[0,1], y=train_labels)\n",
        "\n",
        "print(class_wts)\n",
        "\n",
        "weights= torch.tensor(class_wts,dtype=torch.float)\n",
        "weights = weights.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-08T20:31:12.326226Z",
          "iopub.status.busy": "2023-08-08T20:31:12.325206Z",
          "iopub.status.idle": "2023-08-08T20:31:12.346335Z",
          "shell.execute_reply": "2023-08-08T20:31:12.345262Z",
          "shell.execute_reply.started": "2023-08-08T20:31:12.326196Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WE6DaksWxvLi",
        "outputId": "2df02f06-7975-4ce1-e27d-77e9538d4048"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "WiC_Head(\n",
              "  (model): XLMRobertaForSequenceClassification(\n",
              "    (roberta): XLMRobertaModel(\n",
              "      (embeddings): XLMRobertaEmbeddings(\n",
              "        (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
              "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "        (token_type_embeddings): Embedding(1, 768)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (encoder): XLMRobertaEncoder(\n",
              "        (layer): ModuleList(\n",
              "          (0-11): 12 x XLMRobertaLayer(\n",
              "            (attention): XLMRobertaAttention(\n",
              "              (self): XLMRobertaSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): XLMRobertaSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): XLMRobertaIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): XLMRobertaOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (classifier): XLMRobertaClassificationHead(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "      (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (linear_diff): Linear(in_features=768, out_features=100, bias=True)\n",
              "  (linear_seperator): Linear(in_features=100, out_features=2, bias=True)\n",
              "  (loss): CrossEntropyLoss()\n",
              "  (activation): ReLU()\n",
              "  (softmax): Softmax(dim=None)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "class_model = WiC_Head(model, weights,embedding_size = 768)\n",
        "\n",
        "class_model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFnDB-o_xvLj"
      },
      "source": [
        "## Optimization Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FvOUhiUxvLj"
      },
      "source": [
        "I used an improved version of the Adam Optimizer called AdamW for the below reasons:\n",
        "\n",
        "AdamW is an adaptation of the Adam optimizer, designed to incorporate the weight decay (L2 regularization) term directly into the optimization process. The \"W\" in AdamW stands for \"weight decay.\" Here's why AdamW is commonly used:\n",
        "\n",
        "Weight Decay: Weight decay is a regularization technique that adds a penalty term to the loss function proportional to the sum of squared weights. This term discourages large weight values, preventing overfitting. AdamW efficiently incorporates weight decay into the optimization algorithm, providing better regularization compared to applying weight decay separately.\n",
        "\n",
        "Correcting Biased Estimates: Adam optimizer may have biased updates, especially in the early training stages. AdamW corrects these biased updates by decoupling weight decay from the learning rate.\n",
        "\n",
        "Empirical Success: AdamW has been found to work well in many deep learning tasks and architectures, demonstrating robustness and improved generalization performance in comparison to standard Adam or SGD with weight decay."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-08T20:31:16.625557Z",
          "iopub.status.busy": "2023-08-08T20:31:16.624017Z",
          "iopub.status.idle": "2023-08-08T20:31:16.636605Z",
          "shell.execute_reply": "2023-08-08T20:31:16.635544Z",
          "shell.execute_reply.started": "2023-08-08T20:31:16.625483Z"
        },
        "id": "o7oOUJTTxvLj"
      },
      "outputs": [],
      "source": [
        "\n",
        "param_optimizer = list(class_model.named_parameters())\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.0}\n",
        "]\n",
        "\n",
        "optimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr=1e-5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjcU8lHqxvLk"
      },
      "source": [
        "## Fine Tune the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-08T20:31:24.565893Z",
          "iopub.status.busy": "2023-08-08T20:31:24.565492Z",
          "iopub.status.idle": "2023-08-08T20:31:24.570969Z",
          "shell.execute_reply": "2023-08-08T20:31:24.569912Z",
          "shell.execute_reply.started": "2023-08-08T20:31:24.565859Z"
        },
        "id": "w6JeUtCixvLk"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-08T20:31:25.139008Z",
          "iopub.status.busy": "2023-08-08T20:31:25.138213Z",
          "iopub.status.idle": "2023-08-08T20:36:15.047299Z",
          "shell.execute_reply": "2023-08-08T20:36:15.046434Z",
          "shell.execute_reply.started": "2023-08-08T20:31:25.138978Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arcjljGqxvLk",
        "outputId": "b6ee7270-674b-4566-a0a2-be1449eb510a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch #1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-d3ae0b3d8a91>:42: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  logits = self.softmax(self.linear_seperator(layer1_results))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:\n",
            "\tLoss: 0.6886309054162767; Accuracy: 0.5260942760942762\n",
            "Validation:\n",
            "\tLoss=0.6875538349151611; Accuracy: 0.5475\n",
            "Training epoch #2\n",
            "Training:\n",
            "\tLoss: 0.66914960170033; Accuracy: 0.5840698653198653\n",
            "Validation:\n",
            "\tLoss=0.6787561917304993; Accuracy: 0.585\n",
            "Training epoch #3\n",
            "Training:\n",
            "\tLoss: 0.6471284200446774; Accuracy: 0.6321548821548821\n",
            "Validation:\n",
            "\tLoss=0.670834195613861; Accuracy: 0.6275\n",
            "Training epoch #4\n",
            "Training:\n",
            "\tLoss: 0.6180769074143786; Accuracy: 0.6658249158249159\n",
            "Validation:\n",
            "\tLoss=0.6667855668067932; Accuracy: 0.6125\n",
            "Training epoch #5\n",
            "Training:\n",
            "\tLoss: 0.5814631891371024; Accuracy: 0.7165404040404041\n",
            "Validation:\n",
            "\tLoss=0.6690166676044464; Accuracy: 0.6075\n",
            "Training epoch #6\n",
            "Training:\n",
            "\tLoss: 0.5478233025230542; Accuracy: 0.757996632996633\n",
            "Validation:\n",
            "\tLoss=0.6639060652256012; Accuracy: 0.6325\n",
            "Training epoch #7\n",
            "Training:\n",
            "\tLoss: 0.5121961791406978; Accuracy: 0.7969276094276094\n",
            "Validation:\n",
            "\tLoss=0.6640720105171204; Accuracy: 0.645\n",
            "Training epoch #8\n",
            "Training:\n",
            "\tLoss: 0.4924029725970644; Accuracy: 0.8206018518518517\n",
            "Validation:\n",
            "\tLoss=0.6895757281780243; Accuracy: 0.6125\n",
            "Training epoch #9\n",
            "Training:\n",
            "\tLoss: 0.4738389921910835; Accuracy: 0.8362794612794613\n",
            "Validation:\n",
            "\tLoss=0.6819043469429016; Accuracy: 0.6025\n",
            "Training epoch #10\n",
            "Training:\n",
            "\tLoss: 0.4510897280591907; Accuracy: 0.8637415824915825\n",
            "Validation:\n",
            "\tLoss=0.6884803235530853; Accuracy: 0.6025\n",
            "Best Validation accuracy (0.645) obtained at epoch #7.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "BATCH_SIZE = 16 #decreased the size until the CPU stops dying\n",
        "EPOCHS = 10 #could do more for higher accuracy buts takes too long\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels, return_predict_correctness = False):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    if return_predict_correctness:\n",
        "        return np.sum(pred_flat == labels_flat) / len(labels_flat), pred_flat == labels_flat\n",
        "    else:\n",
        "        return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "best_weights = class_model.state_dict()\n",
        "logits_train=[]\n",
        "labels_train=[]\n",
        "logits_test=[]\n",
        "labels_test=[]\n",
        "\n",
        "# maximize from 0\n",
        "max_val_acc = (0, 0)\n",
        "\n",
        "# Store our loss and accuracy for plotting\n",
        "train_loss=[]\n",
        "train_accuracy=[]\n",
        "val_loss=[]\n",
        "val_accuracy=[]\n",
        "epoch_number = 0\n",
        "\n",
        "while epoch_number < EPOCHS:\n",
        "    epoch_number += 1\n",
        "    print(f\"Training epoch #{epoch_number}\")\n",
        "\n",
        "    # Tracking variables\n",
        "    tr_loss, tr_accuracy = 0, 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "    # Training\n",
        "    class_model.train()\n",
        "\n",
        "    #class_model.embedder.requires_grad_ = False\n",
        "    # Train the data for each epoch\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        b_input_ids, b_input_mask, b_word1, b_word2, b_labels = batch\n",
        "        #reset gradient\n",
        "        optimizer.zero_grad()\n",
        "        # get input and compute loss\n",
        "        b_input_ids = b_input_ids.to(device)\n",
        "        b_input_mask = b_input_mask.to(device)\n",
        "        b_word1 = b_word1.to(device)\n",
        "        b_word2 = b_word2.to(device)\n",
        "        b_labels=b_labels.to(device)\n",
        "        loss, logits = class_model(input_ids=b_input_ids, attention_mask=b_input_mask, word1_locs = b_word1, word2_locs = b_word2,labels=b_labels)\n",
        "        torch.cuda.empty_cache()\n",
        "        # get gradient\n",
        "        loss.backward()\n",
        "        #accelerator.backward(loss)\n",
        "        # Update model\n",
        "        optimizer.step()\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        logits_train.append(logits)\n",
        "        label_ids = b_labels.cpu().numpy()\n",
        "        labels_train.append(label_ids)\n",
        "        # Calculate the accuracy\n",
        "        b_accuracy = flat_accuracy(logits, label_ids) # For RobertaForClassification\n",
        "        # Append to fit history\n",
        "        train_loss.append(loss.item())\n",
        "        train_accuracy.append(b_accuracy)\n",
        "        # Update tracking variables\n",
        "        tr_loss += loss.item()\n",
        "        tr_accuracy += b_accuracy\n",
        "        nb_tr_examples += b_input_ids.size(0)\n",
        "        nb_tr_steps += 1\n",
        "\n",
        "    print(\"Training:\\n\\tLoss: {}; Accuracy: {}\".format(tr_loss/nb_tr_steps, tr_accuracy/nb_tr_steps))\n",
        "\n",
        "    # Validation\n",
        "    class_model.eval()\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in val_dataloader:\n",
        "        b_input_ids, b_input_mask, b_word1, b_word2, b_labels  = batch\n",
        "        # don't store gradients\n",
        "        with torch.no_grad():\n",
        "          # get input and compute loss\n",
        "            loss, logits = class_model(b_input_ids, attention_mask=b_input_mask, word1_locs = b_word1, word2_locs = b_word2,labels=b_labels)\n",
        "            #print(logits)\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        logits_test.append(logits)\n",
        "        label_ids = b_labels.cpu().numpy()\n",
        "        labels_test.append(label_ids)\n",
        "        # Calculate the accuracy\n",
        "        b_accuracy = flat_accuracy(logits, label_ids) # For RobertaForClassification\n",
        "\n",
        "        # Append to fit history\n",
        "        val_loss.append(loss.item())\n",
        "        val_accuracy.append(b_accuracy)\n",
        "        # Update tracking variables\n",
        "        eval_loss += loss.item()\n",
        "        eval_accuracy += b_accuracy\n",
        "        nb_eval_examples += b_input_ids.size(0)\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    eval_acc = eval_accuracy/nb_eval_steps\n",
        "    if eval_acc >= max_val_acc[0]:\n",
        "        max_val_acc = (eval_acc, epoch_number)\n",
        "\n",
        "    print(\"Validation:\\n\\tLoss={}; Accuracy: {}\".format(eval_loss/nb_eval_steps, eval_accuracy/nb_eval_steps))\n",
        "print(f\"Best Validation accuracy ({max_val_acc[0]}) obtained at epoch #{max_val_acc[1]}.\")\n",
        "# Reload the best weights (from memory)\n",
        "class_model.load_state_dict(best_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-08T20:55:45.678173Z",
          "iopub.status.busy": "2023-08-08T20:55:45.677726Z",
          "iopub.status.idle": "2023-08-08T20:55:47.484321Z",
          "shell.execute_reply": "2023-08-08T20:55:47.483064Z",
          "shell.execute_reply.started": "2023-08-08T20:55:45.678133Z"
        },
        "id": "r6dvP-y1xvLk"
      },
      "outputs": [],
      "source": [
        "PATH = 'saved_weights_xlmr_1.pt'\n",
        "torch.save(class_model.state_dict(), PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pl-LZMcxvLl"
      },
      "source": [
        "## Test the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-08T20:59:22.978899Z",
          "iopub.status.busy": "2023-08-08T20:59:22.978522Z",
          "iopub.status.idle": "2023-08-08T20:59:23.074524Z",
          "shell.execute_reply": "2023-08-08T20:59:23.073286Z",
          "shell.execute_reply.started": "2023-08-08T20:59:22.978873Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBhzkKzZxvLl",
        "outputId": "a821c924-bed6-4342-ca6d-ed82623bc8db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  target_word  word_index                                  context_instance1  \\\n",
            "0       उत्तर           5   जमशेदपुर : केंद्रीय माध्यमिक शिक्षा बोर्ड की ...   \n",
            "1         अंग           1   हाथ के किसी उपकरण (औजार) से किसी चीज को इच्छि...   \n",
            "2         कलम           8   कलम ो को अलगअलग गुच्छों में बांध लेते हैं और ...   \n",
            "3        कमान           7   इंका और हरियाणा संघर्ष समिति के बीच निर्णायक ...   \n",
            "4         मूल          49   ज्येष्ठा मूल या अश्विनी नक्षत्र में जन्म लेने...   \n",
            "5         लाल          50   लाल रंग खेल कूद में आपकी क्षमता को भी बढाने व...   \n",
            "6          दर          38   महीने में खुले बाजार में बिकने वाली चीनी के थ...   \n",
            "7       ग्राम          18   भौतिक डिलीवरी के बारे में सिन्हा ने बताया कि ...   \n",
            "8         तिल          32                                               नाक:   \n",
            "9          मत          46   घटनाक्रम के अन्तर्गत बुद्ध को विभिन्न मुद्राओ...   \n",
            "\n",
            "                                   context_instance2 start1 end1 start2 end2  \\\n",
            "0   दिशाओं का निर्धारण उत्तर से होना चाहिए इसके ल...    734  387    206  160   \n",
            "1   बैंकिंग पत्राचार का स्वरूप एवं क्षेत्रबैंकिंग...    571  333    482  394   \n",
            "2   वराहमिहिर ने जमीन की तैयारी एक पेड़ की कलम को ...    745  566    227   42   \n",
            "3   रही बात संगठन के मुखिया दिग्विजय सिंह की तो इ...    563  331    552  362   \n",
            "4   एक अन्य मुद्रा विनिमय संरचना उपरोक्त मूल धन क...    336  298    948  645   \n",
            "5   इनके पीछे गांव के लोग आ रहे थे . गाँव की सीमा...    683  658    504  318   \n",
            "6   इराक़ बारबार कहता आया है कि वह हथियार निरीक्ष...    795  663    581  566   \n",
            "7   (त) ग्राम सभा की सहमति के बिना राज्य सरकार कि...    611  276    339  324   \n",
            "8                                आँख नेत्र अथवा नयन:      6    0     22    0   \n",
            "9   प्रत्येक उम्मीदवार को मिले कुल मान्य मत ों की...    411  319    529  455   \n",
            "\n",
            "   labels  \n",
            "0       0  \n",
            "1       0  \n",
            "2       1  \n",
            "3       1  \n",
            "4       0  \n",
            "5       0  \n",
            "6       0  \n",
            "7       0  \n",
            "8       1  \n",
            "9       0  \n"
          ]
        }
      ],
      "source": [
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"hindi-wsd_test.csv\")\n",
        "\n",
        "print(df.head(10))\n",
        "df1=df.sample(2000)\n",
        "\n",
        "\n",
        "sentences1= df1.context_instance1.values\n",
        "sentences2= df1.context_instance2.values\n",
        "words= df1.target_word.values\n",
        "labels = df1.labels.values"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below section is separate from the above one as the English dataset and Hindi dataset are preprocessed differently"
      ],
      "metadata": {
        "id": "U4xMi2o1FVfJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-08T20:59:25.123367Z",
          "iopub.status.busy": "2023-08-08T20:59:25.122842Z",
          "iopub.status.idle": "2023-08-08T20:59:25.141199Z",
          "shell.execute_reply": "2023-08-08T20:59:25.140005Z",
          "shell.execute_reply.started": "2023-08-08T20:59:25.123327Z"
        },
        "id": "4OKC1MmOxvLm"
      },
      "outputs": [],
      "source": [
        "def find_indexes_before(list1, list2):\n",
        "    index = 0\n",
        "    while index <= len(list1) - len(list2):\n",
        "        if list1[index:index + len(list2)] == list2:\n",
        "            return list(range(index, index + len(list2)))\n",
        "        index += 1\n",
        "    return []\n",
        "\n",
        "def find_indexes_after(list1, before_length,list2):\n",
        "    index = 0\n",
        "    while index <= len(list1) - len(list2):\n",
        "        if list1[index:index + len(list2)] == list2:\n",
        "            #print(index)\n",
        "            return list(range(index +before_length, index +before_length +  len(list2)))\n",
        "        index += 1\n",
        "    return []\n",
        "\n",
        "def create_data_set(sentences1,sentences2,target_word,labels):\n",
        "    wic_padded=[]\n",
        "    for i in range(0,len(sentences1)):\n",
        "\n",
        "        #print(words[i])\n",
        "        #sentence = f\"[CLS] {sentences1[i]} [SEP] {sentences2[i]} [SEP]\"\n",
        "        sentence = f\"<s> {sentences1[i]}</s><s>{sentences2[i]}</s>\"\n",
        "        #print(sentence)\n",
        "        tokens=tokenizer(sentence, add_special_tokens=False,pad_to_max_length=True,\n",
        "                  truncation=True,max_length=512)\n",
        "        input_ids = tokens[\"input_ids\"]\n",
        "        attention_mask = tokens[\"attention_mask\"]\n",
        "        #print(input_ids)\n",
        "        target_word=words[i]\n",
        "        target_token = tokenizer.encode(target_word)\n",
        "        target_token=target_token[1:-1]\n",
        "        s_token_index = tokenizer.convert_tokens_to_ids('</s>')\n",
        "        sep_occurrences = [index for index, token_id in enumerate(input_ids) if token_id == s_token_index]\n",
        "\n",
        "        #sep_occurrences = [index for index, token_id in enumerate(input_ids) if token_id == tokenizer.sep_token_id]\n",
        "\n",
        "        #print(tokenizer.sep_token_id)\n",
        "        if len(sep_occurrences)!=0:\n",
        "            sep_index = sep_occurrences[0]\n",
        "\n",
        "            tokens_before_sep = input_ids[:sep_index]\n",
        "            tokens_after_sep = input_ids[sep_index + 1:]\n",
        "            #print(tokens_before_sep,tokens_after_sep)\n",
        "            is_present1= str(target_token).replace(\"[\",\"\").replace(\"]\",\"\") in str(tokens_before_sep)\n",
        "            is_present2= str(target_token).replace(\"[\",\"\").replace(\"]\",\"\") in str(tokens_after_sep)\n",
        "            #print(target_token)\n",
        "            #print(is_present1,is_present2)\n",
        "            if is_present1!=False and is_present2!=False:\n",
        "                target_word_ids_before_sep = find_indexes_before(tokens_before_sep,target_token)\n",
        "                target_word_ids_after_sep = find_indexes_after(tokens_after_sep,len(tokens_before_sep)-1,target_token)\n",
        "\n",
        "\n",
        "                mask_tensor_sent1 = torch.zeros_like(torch.tensor(input_ids))\n",
        "                mask_tensor_sent1[target_word_ids_before_sep] = 1\n",
        "                mask_tensor_sent2 = torch.zeros_like(torch.tensor(input_ids))\n",
        "                mask_tensor_sent2[target_word_ids_after_sep] = 1\n",
        "                sample_data = {\n",
        "                                \"input_ids\": torch.tensor(input_ids),\n",
        "                                \"attention_mask\": torch.tensor(attention_mask),\n",
        "                                \"word1_locs\": mask_tensor_sent1,\n",
        "                                \"word2_locs\": mask_tensor_sent2,\n",
        "                                \"labels\": torch.tensor(labels[i]),\n",
        "                                \"sentence\": sentence,\n",
        "                                \"target_word\":words[i]\n",
        "                            }\n",
        "\n",
        "                # Append the data for the current sample to the list\n",
        "                wic_padded.append(sample_data)\n",
        "    return wic_padded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-08T20:59:26.459384Z",
          "iopub.status.busy": "2023-08-08T20:59:26.459042Z",
          "iopub.status.idle": "2023-08-08T20:59:31.808203Z",
          "shell.execute_reply": "2023-08-08T20:59:31.806922Z",
          "shell.execute_reply.started": "2023-08-08T20:59:26.459358Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDDDeuXsxvLm",
        "outputId": "e0294177-5c34-4aed-f6a6-ef66f1cee1de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "#create test dataset\n",
        "\n",
        "wic_test_set = create_data_set(sentences1,sentences2,words,labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-08T21:00:25.413118Z",
          "iopub.status.busy": "2023-08-08T21:00:25.412771Z",
          "iopub.status.idle": "2023-08-08T21:00:25.456691Z",
          "shell.execute_reply": "2023-08-08T21:00:25.455787Z",
          "shell.execute_reply.started": "2023-08-08T21:00:25.413092Z"
        },
        "id": "MxYTqaLbxvLm"
      },
      "outputs": [],
      "source": [
        "test_data = TensorDataset(\n",
        "    torch.stack([sample[\"input_ids\"] for sample in wic_test_set]),\n",
        "    torch.stack([sample[\"attention_mask\"] for sample in wic_test_set]),\n",
        "    torch.stack([sample[\"word1_locs\"] for sample in wic_test_set]),\n",
        "    torch.stack([sample[\"word2_locs\"] for sample in wic_test_set]),\n",
        "    torch.stack([sample[\"labels\"] for sample in wic_test_set])\n",
        ")\n",
        "\n",
        "# Create a sampler and loader\n",
        "test_sampler = RandomSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-08T21:00:27.068388Z",
          "iopub.status.busy": "2023-08-08T21:00:27.067800Z",
          "iopub.status.idle": "2023-08-08T21:00:27.087649Z",
          "shell.execute_reply": "2023-08-08T21:00:27.086279Z",
          "shell.execute_reply.started": "2023-08-08T21:00:27.068303Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_-B4fquxvLn",
        "outputId": "9a33b8a6-9000-44e4-ea1f-694451780129"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1930\n"
          ]
        }
      ],
      "source": [
        "print(len(wic_test_set))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-08T05:45:21.641272Z",
          "iopub.status.busy": "2023-08-08T05:45:21.640363Z",
          "iopub.status.idle": "2023-08-08T05:45:22.528863Z",
          "shell.execute_reply": "2023-08-08T05:45:22.528195Z",
          "shell.execute_reply.started": "2023-08-08T05:45:21.641228Z"
        },
        "id": "KNwwj60kxvLn",
        "outputId": "9f075dfe-9407-43ee-a59b-cbbe53d5afd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-2dfe0f0e18fa>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#load weights of best model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'saved_weights_muril.pt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclass_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    792\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'saved_weights_muril.pt'"
          ]
        }
      ],
      "source": [
        "#load weights of best model\n",
        "path = 'saved_weights_muril.pt'\n",
        "class_model.load_state_dict(torch.load(path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-08T21:00:32.946658Z",
          "iopub.status.busy": "2023-08-08T21:00:32.946285Z",
          "iopub.status.idle": "2023-08-08T21:01:54.987417Z",
          "shell.execute_reply": "2023-08-08T21:01:54.986157Z",
          "shell.execute_reply.started": "2023-08-08T21:00:32.946658Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5mDzeXmxvLn",
        "outputId": "567cfa15-9b72-43be-fda7-5327b2e22b96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-d3ae0b3d8a91>:42: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  logits = self.softmax(self.linear_seperator(layer1_results))\n"
          ]
        }
      ],
      "source": [
        "# get predictions for test data\n",
        "class_model.eval()\n",
        "total_preds=[]\n",
        "test_labels1=[]\n",
        "with torch.no_grad():\n",
        "    for batch in test_dataloader:\n",
        "        batch = [t.to(device) for t in batch]\n",
        "        test_ids, test_mask, test_word1, test_word2, test_labels = batch\n",
        "        _,logits = class_model(test_ids, test_mask, test_word1, test_word2, test_labels)\n",
        "        logits=logits.detach().cpu().numpy()\n",
        "        test_labels1.append(test_labels.detach().cpu().numpy())\n",
        "        #print(logits)\n",
        "        preds = np.argmax(logits, axis=1).flatten()\n",
        "        total_preds.append(preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-08T21:24:45.131719Z",
          "iopub.status.busy": "2023-08-08T21:24:45.131219Z",
          "iopub.status.idle": "2023-08-08T21:24:45.139644Z",
          "shell.execute_reply": "2023-08-08T21:24:45.138179Z",
          "shell.execute_reply.started": "2023-08-08T21:24:45.131680Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWdkKMJPxvLn",
        "outputId": "7eaec725-cd8d-4f5b-8700-0712526e72d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1930\n",
            "1930\n"
          ]
        }
      ],
      "source": [
        "total_preds1=[]\n",
        "for i in total_preds:\n",
        "    for i1 in i:\n",
        "        total_preds1.append(i1)\n",
        "\n",
        "print(len(total_preds1))\n",
        "\n",
        "test_labels2=[]\n",
        "for i in test_labels1:\n",
        "    for i1 in i:\n",
        "        test_labels2.append(i1)\n",
        "\n",
        "print(len(test_labels2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-08T21:24:46.722367Z",
          "iopub.status.busy": "2023-08-08T21:24:46.722022Z",
          "iopub.status.idle": "2023-08-08T21:24:46.737340Z",
          "shell.execute_reply": "2023-08-08T21:24:46.736393Z",
          "shell.execute_reply.started": "2023-08-08T21:24:46.722342Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oXlkYm5xvLo",
        "outputId": "e57a4225-f107-4509-cb79-b90b4d181d76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.50      0.56      1094\n",
            "           1       0.49      0.63      0.55       836\n",
            "\n",
            "    accuracy                           0.56      1930\n",
            "   macro avg       0.57      0.57      0.56      1930\n",
            "weighted avg       0.58      0.56      0.56      1930\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# model's performance\n",
        "#preds = np.argmax(preds, axis = 1)\n",
        "print(classification_report(test_labels2, total_preds1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q3sQB3ezxvLo"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1285ba33c84e433ebb7bad7c65a7786b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_18eb570aedd54c25b639ae20ed6a7dd4",
              "IPY_MODEL_63a2b01df7de467982dddb133172ae00",
              "IPY_MODEL_45515774e49e4c31bffffbacbe50da7e"
            ],
            "layout": "IPY_MODEL_541a6ef8a939449394bb44b502a3e565"
          }
        },
        "18eb570aedd54c25b639ae20ed6a7dd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f75049eac5534077a819d7ed2cdcf941",
            "placeholder": "​",
            "style": "IPY_MODEL_da97aa5771d94756b154fb4faea61c1a",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "63a2b01df7de467982dddb133172ae00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fafd13f82f0c4aa2934b266915721516",
            "max": 615,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c94d9f4f0c4a458eb998d1a44687a334",
            "value": 615
          }
        },
        "45515774e49e4c31bffffbacbe50da7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b94c72ce11d342c4b2857b60c87b6d54",
            "placeholder": "​",
            "style": "IPY_MODEL_11d25617b73e458fb203e270eaab250f",
            "value": " 615/615 [00:00&lt;00:00, 49.0kB/s]"
          }
        },
        "541a6ef8a939449394bb44b502a3e565": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f75049eac5534077a819d7ed2cdcf941": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da97aa5771d94756b154fb4faea61c1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fafd13f82f0c4aa2934b266915721516": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c94d9f4f0c4a458eb998d1a44687a334": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b94c72ce11d342c4b2857b60c87b6d54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11d25617b73e458fb203e270eaab250f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b3b8d95f17642c1bed815e97f0e14f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_22c1cc728c2b41d4898933121c9f2fe8",
              "IPY_MODEL_cb98d29d981148a3b5c494fbee3eb92a",
              "IPY_MODEL_5e5601f8691249bd9480c456f9e354ab"
            ],
            "layout": "IPY_MODEL_b5bc9cf4a1a34412b318fe9084d0a779"
          }
        },
        "22c1cc728c2b41d4898933121c9f2fe8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d642308d57f443828c7de94a8e73a126",
            "placeholder": "​",
            "style": "IPY_MODEL_0338d6144d764f198ac61ee8c9e9bdf9",
            "value": "Downloading (…)tencepiece.bpe.model: 100%"
          }
        },
        "cb98d29d981148a3b5c494fbee3eb92a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_481a6d719ee74937bc8fe6800194a12f",
            "max": 5069051,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_67635a8a2ea2490b875c775a15850707",
            "value": 5069051
          }
        },
        "5e5601f8691249bd9480c456f9e354ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_616def7743554c3c893c45d66c9f20f4",
            "placeholder": "​",
            "style": "IPY_MODEL_d8b3f21a5d3a4acf855e46836ca48751",
            "value": " 5.07M/5.07M [00:01&lt;00:00, 5.00MB/s]"
          }
        },
        "b5bc9cf4a1a34412b318fe9084d0a779": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d642308d57f443828c7de94a8e73a126": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0338d6144d764f198ac61ee8c9e9bdf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "481a6d719ee74937bc8fe6800194a12f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67635a8a2ea2490b875c775a15850707": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "616def7743554c3c893c45d66c9f20f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8b3f21a5d3a4acf855e46836ca48751": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e8b67e3684c437c9d2e6e0a4b2a8ab5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e064157216534f3bab41eb8d7e6b82eb",
              "IPY_MODEL_d162fb82de114ddaa71c051aa8fef1ed",
              "IPY_MODEL_f4932b80fe724bda8d493c0eba9d8a28"
            ],
            "layout": "IPY_MODEL_db49a123f6764db1a89db7973e48c40e"
          }
        },
        "e064157216534f3bab41eb8d7e6b82eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee41a4d3be2a4b07914add6d0c70e562",
            "placeholder": "​",
            "style": "IPY_MODEL_e335c757e5454cab8f68ccfc722bbfee",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "d162fb82de114ddaa71c051aa8fef1ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e971ac16ad4d4bc0b8eda6c25c9a04a2",
            "max": 9096718,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a05021b7ad3748ca852d7900e19e328e",
            "value": 9096718
          }
        },
        "f4932b80fe724bda8d493c0eba9d8a28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_baee3fcb5d504e209bb9b28733a69554",
            "placeholder": "​",
            "style": "IPY_MODEL_4507b375f0934e6da8fe176ec4c8661e",
            "value": " 9.10M/9.10M [00:00&lt;00:00, 16.9MB/s]"
          }
        },
        "db49a123f6764db1a89db7973e48c40e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee41a4d3be2a4b07914add6d0c70e562": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e335c757e5454cab8f68ccfc722bbfee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e971ac16ad4d4bc0b8eda6c25c9a04a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a05021b7ad3748ca852d7900e19e328e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "baee3fcb5d504e209bb9b28733a69554": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4507b375f0934e6da8fe176ec4c8661e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ee4abd09365479db3b86cc2106de9e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e9109ee6f7a8414d8450169413e3f281",
              "IPY_MODEL_0a3f8f8c15b6494b8ddbcdd4fe996ebe",
              "IPY_MODEL_52686a3a893b47c4b95485e9f45dc685"
            ],
            "layout": "IPY_MODEL_a10959b28e7642588741b0e9f344ecb2"
          }
        },
        "e9109ee6f7a8414d8450169413e3f281": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d7222be685741328e7fd332fb615b15",
            "placeholder": "​",
            "style": "IPY_MODEL_90c6de5ce888439d90ddf9ab740d81e0",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "0a3f8f8c15b6494b8ddbcdd4fe996ebe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f163fdef65d24fb7bcec80d6bde4b669",
            "max": 1115567652,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2f055de872e14133b294c7c36a2a5b77",
            "value": 1115567652
          }
        },
        "52686a3a893b47c4b95485e9f45dc685": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d4c66d9847e421c80b10cfffe940aec",
            "placeholder": "​",
            "style": "IPY_MODEL_39d7b26d0e92491a9600ae42a31cdf68",
            "value": " 1.12G/1.12G [00:04&lt;00:00, 253MB/s]"
          }
        },
        "a10959b28e7642588741b0e9f344ecb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d7222be685741328e7fd332fb615b15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90c6de5ce888439d90ddf9ab740d81e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f163fdef65d24fb7bcec80d6bde4b669": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f055de872e14133b294c7c36a2a5b77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6d4c66d9847e421c80b10cfffe940aec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39d7b26d0e92491a9600ae42a31cdf68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}