{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h-_8E_tKxvLV"
   },
   "source": [
    "## Choose Devise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-25T01:14:25.994174Z",
     "iopub.status.busy": "2023-08-25T01:14:25.993910Z",
     "iopub.status.idle": "2023-08-25T01:14:26.717137Z",
     "shell.execute_reply": "2023-08-25T01:14:26.716409Z",
     "shell.execute_reply.started": "2023-08-25T01:14:25.994154Z"
    },
    "id": "TXE-_ZQaxvLX",
    "outputId": "45322652-88fe-466f-b283-fc33d46ecbe6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA RTX A4000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():\n",
    "\n",
    "    # Tell PyTorch to use the GPU.\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vQvdqslPxvLa"
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-25T01:14:28.065421Z",
     "iopub.status.busy": "2023-08-25T01:14:28.064643Z",
     "iopub.status.idle": "2023-08-25T01:14:31.724658Z",
     "shell.execute_reply": "2023-08-25T01:14:31.723707Z",
     "shell.execute_reply.started": "2023-08-25T01:14:28.065387Z"
    },
    "id": "kz5vbw7oxvLa",
    "outputId": "80b30641-32fc-49d8-a4da-07c263b9e28b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-transformers\n",
      "  Downloading pytorch_transformers-1.2.0-py3-none-any.whl (176 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.4/176.4 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sacremoses\n",
      "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m88.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.9/dist-packages (from pytorch-transformers) (1.24.90)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from pytorch-transformers) (4.64.1)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.9/dist-packages (from pytorch-transformers) (0.1.97)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from pytorch-transformers) (1.23.4)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.9/dist-packages (from pytorch-transformers) (2022.10.31)\n",
      "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from pytorch-transformers) (1.12.1+cu116)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from pytorch-transformers) (2.28.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.0.0->pytorch-transformers) (4.4.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.9/dist-packages (from boto3->pytorch-transformers) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from boto3->pytorch-transformers) (0.6.0)\n",
      "Requirement already satisfied: botocore<1.28.0,>=1.27.90 in /usr/local/lib/python3.9/dist-packages (from boto3->pytorch-transformers) (1.27.90)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->pytorch-transformers) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->pytorch-transformers) (2019.11.28)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->pytorch-transformers) (2.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests->pytorch-transformers) (2.1.1)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from sacremoses->pytorch-transformers) (1.14.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from sacremoses->pytorch-transformers) (8.1.3)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from sacremoses->pytorch-transformers) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.9/dist-packages (from botocore<1.28.0,>=1.27.90->boto3->pytorch-transformers) (2.8.2)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895242 sha256=f9e04d5191aa71bc96a3dad421d4ac3ac0f2c8d3ca3eeaf47794a50f580ffad8\n",
      "  Stored in directory: /root/.cache/pip/wheels/42/79/78/5ad3b042cb2d97c294535162cdbaf9b167e3b186eae55ab72d\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: sacremoses, pytorch-transformers\n",
      "Successfully installed pytorch-transformers-1.2.0 sacremoses-0.0.53\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pytorch-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-25T01:14:31.726486Z",
     "iopub.status.busy": "2023-08-25T01:14:31.726211Z",
     "iopub.status.idle": "2023-08-25T01:14:34.083874Z",
     "shell.execute_reply": "2023-08-25T01:14:34.083037Z",
     "shell.execute_reply.started": "2023-08-25T01:14:31.726422Z"
    },
    "id": "KVsXSp8CxvLa",
    "outputId": "70c134e3-a5f3-4d78-988c-97ca53040be6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.21.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.12.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.28.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.23.4)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers) (2019.11.28)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.1.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T01:14:34.085186Z",
     "iopub.status.busy": "2023-08-25T01:14:34.084942Z",
     "iopub.status.idle": "2023-08-25T01:14:34.852032Z",
     "shell.execute_reply": "2023-08-25T01:14:34.851364Z",
     "shell.execute_reply.started": "2023-08-25T01:14:34.085163Z"
    },
    "id": "1UDt2wfWxvLb"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import string\n",
    "import copy\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from sklearn.metrics import classification_report\n",
    "from pytorch_transformers import *\n",
    "import numpy as np\n",
    "import json\n",
    "import collections\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T01:14:34.853763Z",
     "iopub.status.busy": "2023-08-25T01:14:34.853474Z",
     "iopub.status.idle": "2023-08-25T01:14:34.857024Z",
     "shell.execute_reply": "2023-08-25T01:14:34.856375Z",
     "shell.execute_reply.started": "2023-08-25T01:14:34.853745Z"
    },
    "id": "6S9Kji_LxvLb"
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5IpHrvLLxvLc"
   },
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-25T01:14:34.858244Z",
     "iopub.status.busy": "2023-08-25T01:14:34.858074Z",
     "iopub.status.idle": "2023-08-25T01:14:34.896325Z",
     "shell.execute_reply": "2023-08-25T01:14:34.895687Z",
     "shell.execute_reply.started": "2023-08-25T01:14:34.858228Z"
    },
    "id": "TDFjheBPxvLc",
    "outputId": "4614d8b9-b3e8-45e1-f735-3a798f77f1bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5428\n"
     ]
    }
   ],
   "source": [
    "#load_data basically reads in data --> takes in everything from jsonl files\n",
    "def load_data(filename):\n",
    "    data = []\n",
    "    # read in each line and add it to list\n",
    "    with open(filename, mode = \"r\") as file:\n",
    "        for line in file:\n",
    "            data.append(json.loads(line))\n",
    "    return data\n",
    "\n",
    "\n",
    "train_json_objs = load_data(\"train.jsonl\")\n",
    "\n",
    "sentences1=[]\n",
    "sentences2=[]\n",
    "words=[]\n",
    "labels=[]\n",
    "for i in range(0,len(train_json_objs)):\n",
    "    sentences1.append(train_json_objs[i]['sentence1'])\n",
    "    sentences2.append(train_json_objs[i]['sentence2'])\n",
    "    words.append(train_json_objs[i]['word'])\n",
    "    labels.append(train_json_objs[i]['label'])\n",
    "\n",
    "print(len(sentences1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "po_CDYPGxvLc"
   },
   "source": [
    "## Import Model & Model Tokenizer | Model Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KEGqvaqny1A7"
   },
   "source": [
    "### List of models present in the experiment:\n",
    "The below models specified were used for the purpose to understand how the models perform when trained and tested on the Hindi Language:\n",
    "\n",
    "* bert-base-multilingual-cased\n",
    "\n",
    "* xlm-roberta-base\n",
    "\n",
    "Please remove the # character to run the chosen model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 130,
     "referenced_widgets": [
      "1285ba33c84e433ebb7bad7c65a7786b",
      "18eb570aedd54c25b639ae20ed6a7dd4",
      "63a2b01df7de467982dddb133172ae00",
      "45515774e49e4c31bffffbacbe50da7e",
      "541a6ef8a939449394bb44b502a3e565",
      "f75049eac5534077a819d7ed2cdcf941",
      "da97aa5771d94756b154fb4faea61c1a",
      "fafd13f82f0c4aa2934b266915721516",
      "c94d9f4f0c4a458eb998d1a44687a334",
      "b94c72ce11d342c4b2857b60c87b6d54",
      "11d25617b73e458fb203e270eaab250f",
      "4b3b8d95f17642c1bed815e97f0e14f8",
      "22c1cc728c2b41d4898933121c9f2fe8",
      "cb98d29d981148a3b5c494fbee3eb92a",
      "5e5601f8691249bd9480c456f9e354ab",
      "b5bc9cf4a1a34412b318fe9084d0a779",
      "d642308d57f443828c7de94a8e73a126",
      "0338d6144d764f198ac61ee8c9e9bdf9",
      "481a6d719ee74937bc8fe6800194a12f",
      "67635a8a2ea2490b875c775a15850707",
      "616def7743554c3c893c45d66c9f20f4",
      "d8b3f21a5d3a4acf855e46836ca48751",
      "8e8b67e3684c437c9d2e6e0a4b2a8ab5",
      "e064157216534f3bab41eb8d7e6b82eb",
      "d162fb82de114ddaa71c051aa8fef1ed",
      "f4932b80fe724bda8d493c0eba9d8a28",
      "db49a123f6764db1a89db7973e48c40e",
      "ee41a4d3be2a4b07914add6d0c70e562",
      "e335c757e5454cab8f68ccfc722bbfee",
      "e971ac16ad4d4bc0b8eda6c25c9a04a2",
      "a05021b7ad3748ca852d7900e19e328e",
      "baee3fcb5d504e209bb9b28733a69554",
      "4507b375f0934e6da8fe176ec4c8661e"
     ]
    },
    "execution": {
     "iopub.execute_input": "2023-08-25T01:14:34.897254Z",
     "iopub.status.busy": "2023-08-25T01:14:34.897072Z",
     "iopub.status.idle": "2023-08-25T01:14:48.599474Z",
     "shell.execute_reply": "2023-08-25T01:14:48.598877Z",
     "shell.execute_reply.started": "2023-08-25T01:14:34.897237Z"
    },
    "id": "SIUsByIvxvLd",
    "outputId": "b10cb0b6-8372-4ee4-c2c8-b0b1a4633edf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xlm-roberta-base\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5259128317cc47ac969e76ba3f2d9c4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08c0f74388ba450a8af33a5b8f9498ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading sentencepiece.bpe.model:   0%|          | 0.00/4.83M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b99d67f11814176ac4cefc8f65a8e0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/8.68M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n",
    "model_name='bert-base-multilingual-cased'\n",
    "print(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867,
     "referenced_widgets": [
      "7ee4abd09365479db3b86cc2106de9e6",
      "e9109ee6f7a8414d8450169413e3f281",
      "0a3f8f8c15b6494b8ddbcdd4fe996ebe",
      "52686a3a893b47c4b95485e9f45dc685",
      "a10959b28e7642588741b0e9f344ecb2",
      "9d7222be685741328e7fd332fb615b15",
      "90c6de5ce888439d90ddf9ab740d81e0",
      "f163fdef65d24fb7bcec80d6bde4b669",
      "2f055de872e14133b294c7c36a2a5b77",
      "6d4c66d9847e421c80b10cfffe940aec",
      "39d7b26d0e92491a9600ae42a31cdf68"
     ]
    },
    "execution": {
     "iopub.execute_input": "2023-08-25T01:14:48.600685Z",
     "iopub.status.busy": "2023-08-25T01:14:48.600333Z",
     "iopub.status.idle": "2023-08-25T01:15:04.529836Z",
     "shell.execute_reply": "2023-08-25T01:15:04.529139Z",
     "shell.execute_reply.started": "2023-08-25T01:14:48.600667Z"
    },
    "id": "uR9uUiDnxvLd",
    "outputId": "16c63c4f-e367-4417-fccb-1d99dac41d74"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ab3070a671446219fe1d3600a08df07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.04G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XLMRobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
    "    # output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = True, # Whether the model returns all hidden-states.\n",
    ")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TwGwN1I5xvLd"
   },
   "source": [
    "## Create Train Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZLOCkoHwxvLe"
   },
   "source": [
    "The below functions will find the range of indexes of the target words from the two context sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T01:15:04.533087Z",
     "iopub.status.busy": "2023-08-25T01:15:04.532462Z",
     "iopub.status.idle": "2023-08-25T01:15:04.537771Z",
     "shell.execute_reply": "2023-08-25T01:15:04.537350Z",
     "shell.execute_reply.started": "2023-08-25T01:15:04.533058Z"
    },
    "id": "W3uceusJxvLe"
   },
   "outputs": [],
   "source": [
    "def find_indexes_before(list1, list2):\n",
    "    index = 0\n",
    "    while index <= len(list1) - len(list2):\n",
    "        if list1[index:index + len(list2)] == list2:\n",
    "            return list(range(index, index + len(list2)))\n",
    "        index += 1\n",
    "    return []\n",
    "\n",
    "def find_indexes_after(list1, before_length,list2):\n",
    "    index = 0\n",
    "    while index <= len(list1) - len(list2):\n",
    "        if list1[index:index + len(list2)] == list2:\n",
    "            #print(index)\n",
    "            return list(range(index +before_length, index +before_length +  len(list2)))\n",
    "        index += 1\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-25T01:15:29.777135Z",
     "iopub.status.busy": "2023-08-25T01:15:29.776473Z",
     "iopub.status.idle": "2023-08-25T01:15:29.920385Z",
     "shell.execute_reply": "2023-08-25T01:15:29.919742Z",
     "shell.execute_reply.started": "2023-08-25T01:15:29.777109Z"
    },
    "id": "SGHgXfkT0Jit",
    "outputId": "6628834a-4ecb-40c7-fac2-1557155f4751"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T01:15:30.957194Z",
     "iopub.status.busy": "2023-08-25T01:15:30.956592Z",
     "iopub.status.idle": "2023-08-25T01:15:30.960463Z",
     "shell.execute_reply": "2023-08-25T01:15:30.959821Z",
     "shell.execute_reply.started": "2023-08-25T01:15:30.957171Z"
    },
    "id": "e_JzznpAxvLf"
   },
   "outputs": [],
   "source": [
    "# This step is done to preprocess th target words in the English WiC dataset\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ce5vtX_5xvLe"
   },
   "source": [
    "The below function creates the dataset in the required format that is it contains a dictionary of lists with:\n",
    "1. Input IDs -  sequence of integer tokens that represent the input text. Each token in the text is mapped to a unique integer ID based on a tokenizer. BERT uses a fixed-size vocabulary, and each token in the text is converted to its corresponding ID from the vocabulary.\n",
    "\n",
    "2. Attention mask - binary mask tensor that indicates which tokens in the input should be attended to (receive attention) and which tokens should be ignored. It is used to handle variable-length input sequences. The mask has the same length as the input sequence and contains 0s and 1s\n",
    "\n",
    "3. Target Word Location in sentence 1 - used to extract embeddings of target word from sentence 1\n",
    "\n",
    "4. Target Word Location in sentence 2 - used to extract embeddings of target word from sentence 2\n",
    "\n",
    "5. Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T01:15:32.525069Z",
     "iopub.status.busy": "2023-08-25T01:15:32.524372Z",
     "iopub.status.idle": "2023-08-25T01:15:32.534618Z",
     "shell.execute_reply": "2023-08-25T01:15:32.533933Z",
     "shell.execute_reply.started": "2023-08-25T01:15:32.525044Z"
    },
    "id": "Do3CBHW3xvLf"
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_data_set(sentences1,sentences2,target_word,labels):\n",
    "    wic_padded=[]\n",
    "    missed=[]\n",
    "    for i in range(0,len(sentences1)):\n",
    "        lemmatized_tokens=[]\n",
    "        tokens = word_tokenize(sentences1[i])\n",
    "        for t1 in tokens:\n",
    "            lemma = lemmatizer.lemmatize(t1)\n",
    "            lemmatized_tokens.append(lemma.lower())\n",
    "        lemmatized_sentence1 = ' '.join(lemmatized_tokens)\n",
    "\n",
    "        lemmatized_tokens=[]\n",
    "        tokens = word_tokenize(sentences2[i])\n",
    "        for t1 in tokens:\n",
    "            lemma = lemmatizer.lemmatize(t1)\n",
    "            lemmatized_tokens.append(lemma.lower())\n",
    "        lemmatized_sentence2 = ' '.join(lemmatized_tokens)\n",
    "\n",
    "        #print(words[i])\n",
    "        #sentence = f\"[CLS] {lemmatized_sentence1} [SEP] {lemmatized_sentence2} [SEP]\"\n",
    "        sentence = f\"<s> {sentences1[i]}</s><s>{sentences2[i]}</s>\"\n",
    "        #print(sentence)\n",
    "        tokens=tokenizer(sentence, add_special_tokens=False,pad_to_max_length=True,\n",
    "                  truncation=True,max_length=512)\n",
    "        input_ids = tokens[\"input_ids\"]\n",
    "        attention_mask = tokens[\"attention_mask\"]\n",
    "        #print(input_ids)\n",
    "        target_word=words[i]\n",
    "        target_token = tokenizer.encode(target_word)\n",
    "        target_token=target_token[1:-1]\n",
    "\n",
    "        #For XLM-RoBERTa\n",
    "        s_token_index = tokenizer.convert_tokens_to_ids('</s>')\n",
    "        sep_occurrences = [index for index, token_id in enumerate(input_ids) if token_id == s_token_index]\n",
    "\n",
    "        #ANY OTHER MODEL\n",
    "        #sep_occurrences = [index for index, token_id in enumerate(input_ids) if token_id == tokenizer.sep_token_id]\n",
    "\n",
    "        if len(sep_occurrences)!=0:\n",
    "            sep_index = sep_occurrences[0]\n",
    "\n",
    "            tokens_before_sep = input_ids[:sep_index]\n",
    "            tokens_after_sep = input_ids[sep_index + 1:]\n",
    "\n",
    "            is_present1= str(target_token).replace(\"[\",\"\").replace(\"]\",\"\") in str(tokens_before_sep)\n",
    "            is_present2= str(target_token).replace(\"[\",\"\").replace(\"]\",\"\") in str(tokens_after_sep)\n",
    "\n",
    "            if is_present1!=False and is_present2!=False:\n",
    "                target_word_ids_before_sep = find_indexes_before(tokens_before_sep,target_token)\n",
    "                target_word_ids_after_sep = find_indexes_after(tokens_after_sep,len(tokens_before_sep)-1,target_token)\n",
    "                if labels[i]==False:\n",
    "                    label=0\n",
    "                else:\n",
    "                    label=1\n",
    "\n",
    "                mask_tensor_sent1 = torch.zeros_like(torch.tensor(input_ids))\n",
    "                mask_tensor_sent1[target_word_ids_before_sep] = 1\n",
    "                mask_tensor_sent2 = torch.zeros_like(torch.tensor(input_ids))\n",
    "                mask_tensor_sent2[target_word_ids_after_sep] = 1\n",
    "                sample_data = {\n",
    "                                \"input_ids\": torch.tensor(input_ids),\n",
    "                                \"attention_mask\": torch.tensor(attention_mask),\n",
    "                                \"word1_locs\": mask_tensor_sent1,\n",
    "                                \"word2_locs\": mask_tensor_sent2,\n",
    "                                \"labels\": torch.tensor(label),\n",
    "                                \"sentence\": sentence,\n",
    "                                \"target_word\":words[i]\n",
    "                            }\n",
    "\n",
    "                # Append the data for the current sample to the list\n",
    "                wic_padded.append(sample_data)\n",
    "            else:missed.append([sentence, words[i]])\n",
    "        else:missed.append([sentence, words[i]])\n",
    "    return wic_padded,missed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-25T01:15:33.647467Z",
     "iopub.status.busy": "2023-08-25T01:15:33.647169Z",
     "iopub.status.idle": "2023-08-25T01:15:37.513444Z",
     "shell.execute_reply": "2023-08-25T01:15:37.512788Z",
     "shell.execute_reply.started": "2023-08-25T01:15:33.647426Z"
    },
    "id": "NSzmHbKixvLg",
    "outputId": "fac1b469-9e45-4926-b6e4-6422fefd84f4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2323: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#create training dataset\n",
    "\n",
    "wic_train_set,l1 = create_data_set(sentences1,sentences2,words,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T01:15:37.515141Z",
     "iopub.status.busy": "2023-08-25T01:15:37.514582Z",
     "iopub.status.idle": "2023-08-25T01:15:37.518361Z",
     "shell.execute_reply": "2023-08-25T01:15:37.517548Z",
     "shell.execute_reply.started": "2023-08-25T01:15:37.515120Z"
    },
    "id": "z_TWiLH4xvLg"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T01:15:37.645310Z",
     "iopub.status.busy": "2023-08-25T01:15:37.645044Z",
     "iopub.status.idle": "2023-08-25T01:15:37.653013Z",
     "shell.execute_reply": "2023-08-25T01:15:37.652440Z",
     "shell.execute_reply.started": "2023-08-25T01:15:37.645289Z"
    },
    "id": "pWFdCOVSxvLg"
   },
   "outputs": [],
   "source": [
    "train_labels=[]\n",
    "for i in wic_train_set:\n",
    "    x=i[\"labels\"].item()\n",
    "    train_labels.append(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-25T01:15:38.275290Z",
     "iopub.status.busy": "2023-08-25T01:15:38.274604Z",
     "iopub.status.idle": "2023-08-25T01:15:38.282156Z",
     "shell.execute_reply": "2023-08-25T01:15:38.281478Z",
     "shell.execute_reply.started": "2023-08-25T01:15:38.275262Z"
    },
    "id": "FAA1fTHZxvLg",
    "outputId": "97eecc07-dfdd-4e5a-bae6-049ffe90f8cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence:  <s> Do you want to come over to my place later?</s><s>A political system with no place for the less prominent groups.</s>\n",
      "target_word:  place\n",
      "word1 location:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "word2 location:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "for i in wic_train_set:\n",
    "    x=i[\"word1_locs\"]\n",
    "    y=i[\"word2_locs\"]\n",
    "    print(\"sentence: \",i[\"sentence\"])\n",
    "    print(\"target_word: \",i[\"target_word\"])\n",
    "    print(\"word1 location: \",x)\n",
    "    print(\"word2 location: \",y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T01:15:39.167966Z",
     "iopub.status.busy": "2023-08-25T01:15:39.167700Z",
     "iopub.status.idle": "2023-08-25T01:15:39.191692Z",
     "shell.execute_reply": "2023-08-25T01:15:39.191061Z",
     "shell.execute_reply.started": "2023-08-25T01:15:39.167948Z"
    },
    "id": "ZkgDajX2xvLh"
   },
   "outputs": [],
   "source": [
    "train_data = TensorDataset(\n",
    "    torch.stack([sample[\"input_ids\"] for sample in wic_train_set]),\n",
    "    torch.stack([sample[\"attention_mask\"] for sample in wic_train_set]),\n",
    "    torch.stack([sample[\"word1_locs\"] for sample in wic_train_set]),\n",
    "    torch.stack([sample[\"word2_locs\"] for sample in wic_train_set]),\n",
    "    torch.stack([sample[\"labels\"] for sample in wic_train_set])\n",
    ")\n",
    "\n",
    "# Create a sampler and loader\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_D5LUQD9xvLh"
   },
   "source": [
    "## Create Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-25T01:15:40.924536Z",
     "iopub.status.busy": "2023-08-25T01:15:40.923867Z",
     "iopub.status.idle": "2023-08-25T01:15:40.939864Z",
     "shell.execute_reply": "2023-08-25T01:15:40.939231Z",
     "shell.execute_reply.started": "2023-08-25T01:15:40.924512Z"
    },
    "id": "WMG7YVi4xvLh",
    "outputId": "7309ca76-7989-4c12-d291-059970e2dd17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "638\n"
     ]
    }
   ],
   "source": [
    "#load_data basically reads in data --> takes in everything from jsonl files\n",
    "def load_data(filename):\n",
    "    data = []\n",
    "    # read in each line and add it to list\n",
    "    with open(filename, mode = \"r\") as file:\n",
    "        for line in file:\n",
    "            data.append(json.loads(line))\n",
    "    return data\n",
    "\n",
    "\n",
    "train_json_objs = load_data(\"val.jsonl\")\n",
    "\n",
    "sentences1=[]\n",
    "sentences2=[]\n",
    "words=[]\n",
    "labels=[]\n",
    "for i in range(0,len(train_json_objs)):\n",
    "    sentences1.append(train_json_objs[i]['sentence1'])\n",
    "    sentences2.append(train_json_objs[i]['sentence2'])\n",
    "    words.append(train_json_objs[i]['word'])\n",
    "    labels.append(train_json_objs[i]['label'])\n",
    "\n",
    "print(len(sentences1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T01:15:41.391488Z",
     "iopub.status.busy": "2023-08-25T01:15:41.390572Z",
     "iopub.status.idle": "2023-08-25T01:15:41.740993Z",
     "shell.execute_reply": "2023-08-25T01:15:41.740351Z",
     "shell.execute_reply.started": "2023-08-25T01:15:41.391406Z"
    },
    "id": "RtqRYpR7xvLh"
   },
   "outputs": [],
   "source": [
    "#create validation dataset\n",
    "\n",
    "wic_val_set,l1 = create_data_set(sentences1,sentences2,words,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T01:15:41.998476Z",
     "iopub.status.busy": "2023-08-25T01:15:41.997857Z",
     "iopub.status.idle": "2023-08-25T01:15:42.004774Z",
     "shell.execute_reply": "2023-08-25T01:15:42.004272Z",
     "shell.execute_reply.started": "2023-08-25T01:15:41.998451Z"
    },
    "id": "VKaetke1xvLi"
   },
   "outputs": [],
   "source": [
    "\n",
    "val_data = TensorDataset(\n",
    "    torch.stack([sample[\"input_ids\"] for sample in wic_val_set]),\n",
    "    torch.stack([sample[\"attention_mask\"] for sample in wic_val_set]),\n",
    "    torch.stack([sample[\"word1_locs\"] for sample in wic_val_set]),\n",
    "    torch.stack([sample[\"word2_locs\"] for sample in wic_val_set]),\n",
    "    torch.stack([sample[\"labels\"] for sample in wic_val_set])\n",
    ")\n",
    "\n",
    "# Create a sampler and loader\n",
    "val_sampler = RandomSampler(val_data)\n",
    "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0g-xdIHRxvLi"
   },
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T01:15:44.513108Z",
     "iopub.status.busy": "2023-08-25T01:15:44.512194Z",
     "iopub.status.idle": "2023-08-25T01:15:44.521564Z",
     "shell.execute_reply": "2023-08-25T01:15:44.520982Z",
     "shell.execute_reply.started": "2023-08-25T01:15:44.513080Z"
    },
    "id": "XsJAELpmxvLi"
   },
   "outputs": [],
   "source": [
    "\n",
    "class WiC_Head(torch.nn.Module):\n",
    "    def __init__(self, model_used,weights,embedding_size=768):\n",
    "        super(WiC_Head, self).__init__()\n",
    "        self.model=model_used\n",
    "        self.embedding_size = embedding_size\n",
    "        self.linear_diff = torch.nn.Linear(embedding_size, 100, bias=True)\n",
    "        self.linear_seperator = torch.nn.Linear(100, 2, bias=True)\n",
    "        self.loss = torch.nn.CrossEntropyLoss(weight=weights)\n",
    "        self.activation = torch.nn.ReLU()\n",
    "        self.softmax = torch.nn.Softmax()\n",
    "\n",
    "        self.to(device)\n",
    "        self.linear_diff.to(device)\n",
    "        self.loss.to(device)\n",
    "        self.linear_seperator.to(device)\n",
    "        self.activation.to(device)\n",
    "        self.softmax.to(device)\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, word1_locs=None, word2_locs=None, labels=None):\n",
    "        batch_size = input_ids.shape[0]\n",
    "        input_ids_tensor = input_ids.to(device)\n",
    "        attention_mask_tensor = attention_mask.to(device)\n",
    "        word1_locs = word1_locs.to(device)\n",
    "        word1_locs=word1_locs.unsqueeze(1)\n",
    "\n",
    "        word2_locs = word2_locs.to(device)\n",
    "        word2_locs=word2_locs.unsqueeze(1)\n",
    "\n",
    "        outputs=model(input_ids_tensor,attention_mask_tensor)\n",
    "\n",
    "        token_embeddings=outputs.hidden_states[-1]\n",
    "\n",
    "        token_embeddings = torch.squeeze(token_embeddings, dim=0)\n",
    "\n",
    "        word1_embs=torch.matmul(word1_locs.float(),token_embeddings.float()).view(batch_size, self.embedding_size)\n",
    "\n",
    "        word2_embs=torch.matmul(word2_locs.float(),token_embeddings.float()).view(batch_size, self.embedding_size)\n",
    "\n",
    "        diff = word1_embs - word2_embs\n",
    "\n",
    "        layer1_results = self.activation(self.linear_diff(diff))\n",
    "        logits = self.softmax(self.linear_seperator(layer1_results))\n",
    "        if labels is not None:\n",
    "            loss = self.loss(logits.view(-1, 2).to(device), labels.view(-1).to(device))\n",
    "            outputs = (loss, logits)\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3R6D22LSxvLi"
   },
   "source": [
    "We need to ensure that both classes are assigned weights accordingly in case any class in our dataset over represented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-25T01:15:46.731906Z",
     "iopub.status.busy": "2023-08-25T01:15:46.731647Z",
     "iopub.status.idle": "2023-08-25T01:15:46.745374Z",
     "shell.execute_reply": "2023-08-25T01:15:46.744880Z",
     "shell.execute_reply.started": "2023-08-25T01:15:46.731887Z"
    },
    "id": "lBIASO40xvLi",
    "outputId": "eefa3603-229b-4bcf-8ef9-b84db5ad1938"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.07196198 0.93709199]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "#compute the class weights\n",
    "class_wts = compute_class_weight('balanced', classes=[0,1], y=train_labels)\n",
    "\n",
    "print(class_wts)\n",
    "\n",
    "weights= torch.tensor(class_wts,dtype=torch.float)\n",
    "weights = weights.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-25T01:15:47.818823Z",
     "iopub.status.busy": "2023-08-25T01:15:47.818131Z",
     "iopub.status.idle": "2023-08-25T01:15:47.830809Z",
     "shell.execute_reply": "2023-08-25T01:15:47.830348Z",
     "shell.execute_reply.started": "2023-08-25T01:15:47.818794Z"
    },
    "id": "WE6DaksWxvLi",
    "outputId": "2df02f06-7975-4ce1-e27d-77e9538d4048"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WiC_Head(\n",
       "  (model): XLMRobertaForSequenceClassification(\n",
       "    (roberta): RobertaModel(\n",
       "      (embeddings): RobertaEmbeddings(\n",
       "        (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
       "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "        (token_type_embeddings): Embedding(1, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): RobertaEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (classifier): RobertaClassificationHead(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (linear_diff): Linear(in_features=768, out_features=100, bias=True)\n",
       "  (linear_seperator): Linear(in_features=100, out_features=2, bias=True)\n",
       "  (loss): CrossEntropyLoss()\n",
       "  (activation): ReLU()\n",
       "  (softmax): Softmax(dim=None)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_model = WiC_Head(model, weights,embedding_size = 768)\n",
    "\n",
    "class_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TFnDB-o_xvLj"
   },
   "source": [
    "## Optimization Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2FvOUhiUxvLj"
   },
   "source": [
    "I used an improved version of the Adam Optimizer called AdamW for the below reasons:\n",
    "\n",
    "AdamW is an adaptation of the Adam optimizer, designed to incorporate the weight decay (L2 regularization) term directly into the optimization process. The \"W\" in AdamW stands for \"weight decay.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T01:16:01.493667Z",
     "iopub.status.busy": "2023-08-25T01:16:01.493400Z",
     "iopub.status.idle": "2023-08-25T01:16:01.499305Z",
     "shell.execute_reply": "2023-08-25T01:16:01.498562Z",
     "shell.execute_reply.started": "2023-08-25T01:16:01.493648Z"
    },
    "id": "o7oOUJTTxvLj"
   },
   "outputs": [],
   "source": [
    "\n",
    "param_optimizer = list(class_model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.0}\n",
    "]\n",
    "\n",
    "optimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pjcU8lHqxvLk"
   },
   "source": [
    "## Fine Tune the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T01:16:03.604637Z",
     "iopub.status.busy": "2023-08-25T01:16:03.603964Z",
     "iopub.status.idle": "2023-08-25T01:16:03.607423Z",
     "shell.execute_reply": "2023-08-25T01:16:03.606920Z",
     "shell.execute_reply.started": "2023-08-25T01:16:03.604612Z"
    },
    "id": "w6JeUtCixvLk"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-25T01:16:04.558129Z",
     "iopub.status.busy": "2023-08-25T01:16:04.557778Z"
    },
    "id": "arcjljGqxvLk",
    "outputId": "b6ee7270-674b-4566-a0a2-be1449eb510a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/913484304.py:42: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  logits = self.softmax(self.linear_seperator(layer1_results))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "\tLoss: 0.6924933300475882; Accuracy: 0.48874158249158245\n",
      "Validation:\n",
      "\tLoss=0.6908018016815185; Accuracy: 0.5375\n",
      "Training epoch #2\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 16 #decreased the size until the CPU stops dying\n",
    "EPOCHS = 10 #could do more for higher accuracy buts takes too long\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels, return_predict_correctness = False):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    if return_predict_correctness:\n",
    "        return np.sum(pred_flat == labels_flat) / len(labels_flat), pred_flat == labels_flat\n",
    "    else:\n",
    "        return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "best_weights = class_model.state_dict()\n",
    "logits_train=[]\n",
    "labels_train=[]\n",
    "logits_test=[]\n",
    "labels_test=[]\n",
    "\n",
    "# maximize from 0\n",
    "max_val_acc = (0, 0)\n",
    "\n",
    "# Store our loss and accuracy for plotting\n",
    "train_loss=[]\n",
    "train_accuracy=[]\n",
    "val_loss=[]\n",
    "val_accuracy=[]\n",
    "epoch_number = 0\n",
    "\n",
    "while epoch_number < EPOCHS:\n",
    "    epoch_number += 1\n",
    "    print(f\"Training epoch #{epoch_number}\")\n",
    "\n",
    "    # Tracking variables\n",
    "    tr_loss, tr_accuracy = 0, 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    # Training\n",
    "    class_model.train()\n",
    "\n",
    "    #class_model.embedder.requires_grad_ = False\n",
    "    # Train the data for each epoch\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        b_input_ids, b_input_mask, b_word1, b_word2, b_labels = batch\n",
    "        #reset gradient\n",
    "        optimizer.zero_grad()\n",
    "        # get input and compute loss\n",
    "        b_input_ids = b_input_ids.to(device)\n",
    "        b_input_mask = b_input_mask.to(device)\n",
    "        b_word1 = b_word1.to(device)\n",
    "        b_word2 = b_word2.to(device)\n",
    "        b_labels=b_labels.to(device)\n",
    "        loss, logits = class_model(input_ids=b_input_ids, attention_mask=b_input_mask, word1_locs = b_word1, word2_locs = b_word2,labels=b_labels)\n",
    "        torch.cuda.empty_cache()\n",
    "        # get gradient\n",
    "        loss.backward()\n",
    "        #accelerator.backward(loss)\n",
    "        # Update model\n",
    "        optimizer.step()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        logits_train.append(logits)\n",
    "        label_ids = b_labels.cpu().numpy()\n",
    "        labels_train.append(label_ids)\n",
    "        # Calculate the accuracy\n",
    "        b_accuracy = flat_accuracy(logits, label_ids) # For RobertaForClassification\n",
    "        # Append to fit history\n",
    "        train_loss.append(loss.item())\n",
    "        train_accuracy.append(b_accuracy)\n",
    "        # Update tracking variables\n",
    "        tr_loss += loss.item()\n",
    "        tr_accuracy += b_accuracy\n",
    "        nb_tr_examples += b_input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "\n",
    "    print(\"Training:\\n\\tLoss: {}; Accuracy: {}\".format(tr_loss/nb_tr_steps, tr_accuracy/nb_tr_steps))\n",
    "\n",
    "    # Validation\n",
    "    class_model.eval()\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in val_dataloader:\n",
    "        b_input_ids, b_input_mask, b_word1, b_word2, b_labels  = batch\n",
    "        # don't store gradients\n",
    "        with torch.no_grad():\n",
    "          # get input and compute loss\n",
    "            loss, logits = class_model(b_input_ids, attention_mask=b_input_mask, word1_locs = b_word1, word2_locs = b_word2,labels=b_labels)\n",
    "            #print(logits)\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        logits_test.append(logits)\n",
    "        label_ids = b_labels.cpu().numpy()\n",
    "        labels_test.append(label_ids)\n",
    "        # Calculate the accuracy\n",
    "        b_accuracy = flat_accuracy(logits, label_ids) # For RobertaForClassification\n",
    "\n",
    "        # Append to fit history\n",
    "        val_loss.append(loss.item())\n",
    "        val_accuracy.append(b_accuracy)\n",
    "        # Update tracking variables\n",
    "        eval_loss += loss.item()\n",
    "        eval_accuracy += b_accuracy\n",
    "        nb_eval_examples += b_input_ids.size(0)\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    eval_acc = eval_accuracy/nb_eval_steps\n",
    "    if eval_acc >= max_val_acc[0]:\n",
    "        max_val_acc = (eval_acc, epoch_number)\n",
    "\n",
    "    print(\"Validation:\\n\\tLoss={}; Accuracy: {}\".format(eval_loss/nb_eval_steps, eval_accuracy/nb_eval_steps))\n",
    "print(f\"Best Validation accuracy ({max_val_acc[0]}) obtained at epoch #{max_val_acc[1]}.\")\n",
    "# Reload the best weights (from memory)\n",
    "class_model.load_state_dict(best_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T20:55:45.678173Z",
     "iopub.status.busy": "2023-08-08T20:55:45.677726Z",
     "iopub.status.idle": "2023-08-08T20:55:47.484321Z",
     "shell.execute_reply": "2023-08-08T20:55:47.483064Z",
     "shell.execute_reply.started": "2023-08-08T20:55:45.678133Z"
    },
    "id": "r6dvP-y1xvLk"
   },
   "outputs": [],
   "source": [
    "PATH = 'saved_weights_xlmr_1.pt'\n",
    "torch.save(class_model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-pl-LZMcxvLl"
   },
   "source": [
    "## Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-08T20:59:22.978899Z",
     "iopub.status.busy": "2023-08-08T20:59:22.978522Z",
     "iopub.status.idle": "2023-08-08T20:59:23.074524Z",
     "shell.execute_reply": "2023-08-08T20:59:23.073286Z",
     "shell.execute_reply.started": "2023-08-08T20:59:22.978873Z"
    },
    "id": "wBhzkKzZxvLl",
    "outputId": "a821c924-bed6-4342-ca6d-ed82623bc8db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  target_word  word_index                                  context_instance1  \\\n",
      "0       उत्तर           5   जमशेदपुर : केंद्रीय माध्यमिक शिक्षा बोर्ड की ...   \n",
      "1         अंग           1   हाथ के किसी उपकरण (औजार) से किसी चीज को इच्छि...   \n",
      "2         कलम           8   कलम ो को अलगअलग गुच्छों में बांध लेते हैं और ...   \n",
      "3        कमान           7   इंका और हरियाणा संघर्ष समिति के बीच निर्णायक ...   \n",
      "4         मूल          49   ज्येष्ठा मूल या अश्विनी नक्षत्र में जन्म लेने...   \n",
      "5         लाल          50   लाल रंग खेल कूद में आपकी क्षमता को भी बढाने व...   \n",
      "6          दर          38   महीने में खुले बाजार में बिकने वाली चीनी के थ...   \n",
      "7       ग्राम          18   भौतिक डिलीवरी के बारे में सिन्हा ने बताया कि ...   \n",
      "8         तिल          32                                               नाक:   \n",
      "9          मत          46   घटनाक्रम के अन्तर्गत बुद्ध को विभिन्न मुद्राओ...   \n",
      "\n",
      "                                   context_instance2 start1 end1 start2 end2  \\\n",
      "0   दिशाओं का निर्धारण उत्तर से होना चाहिए इसके ल...    734  387    206  160   \n",
      "1   बैंकिंग पत्राचार का स्वरूप एवं क्षेत्रबैंकिंग...    571  333    482  394   \n",
      "2   वराहमिहिर ने जमीन की तैयारी एक पेड़ की कलम को ...    745  566    227   42   \n",
      "3   रही बात संगठन के मुखिया दिग्विजय सिंह की तो इ...    563  331    552  362   \n",
      "4   एक अन्य मुद्रा विनिमय संरचना उपरोक्त मूल धन क...    336  298    948  645   \n",
      "5   इनके पीछे गांव के लोग आ रहे थे . गाँव की सीमा...    683  658    504  318   \n",
      "6   इराक़ बारबार कहता आया है कि वह हथियार निरीक्ष...    795  663    581  566   \n",
      "7   (त) ग्राम सभा की सहमति के बिना राज्य सरकार कि...    611  276    339  324   \n",
      "8                                आँख नेत्र अथवा नयन:      6    0     22    0   \n",
      "9   प्रत्येक उम्मीदवार को मिले कुल मान्य मत ों की...    411  319    529  455   \n",
      "\n",
      "   labels  \n",
      "0       0  \n",
      "1       0  \n",
      "2       1  \n",
      "3       1  \n",
      "4       0  \n",
      "5       0  \n",
      "6       0  \n",
      "7       0  \n",
      "8       1  \n",
      "9       0  \n"
     ]
    }
   ],
   "source": [
    "# Load the dataset into a pandas dataframe.\n",
    "df = pd.read_csv(\"hindi-wsd_test.csv\")\n",
    "\n",
    "print(df.head(10))\n",
    "df1=df.sample(2000)\n",
    "\n",
    "\n",
    "sentences1= df1.context_instance1.values\n",
    "sentences2= df1.context_instance2.values\n",
    "words= df1.target_word.values\n",
    "labels = df1.labels.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U4xMi2o1FVfJ"
   },
   "source": [
    "The below section is separate from the above one as the English dataset and Hindi dataset are preprocessed differently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T20:59:25.123367Z",
     "iopub.status.busy": "2023-08-08T20:59:25.122842Z",
     "iopub.status.idle": "2023-08-08T20:59:25.141199Z",
     "shell.execute_reply": "2023-08-08T20:59:25.140005Z",
     "shell.execute_reply.started": "2023-08-08T20:59:25.123327Z"
    },
    "id": "4OKC1MmOxvLm"
   },
   "outputs": [],
   "source": [
    "def find_indexes_before(list1, list2):\n",
    "    index = 0\n",
    "    while index <= len(list1) - len(list2):\n",
    "        if list1[index:index + len(list2)] == list2:\n",
    "            return list(range(index, index + len(list2)))\n",
    "        index += 1\n",
    "    return []\n",
    "\n",
    "def find_indexes_after(list1, before_length,list2):\n",
    "    index = 0\n",
    "    while index <= len(list1) - len(list2):\n",
    "        if list1[index:index + len(list2)] == list2:\n",
    "            #print(index)\n",
    "            return list(range(index +before_length, index +before_length +  len(list2)))\n",
    "        index += 1\n",
    "    return []\n",
    "\n",
    "def create_data_set(sentences1,sentences2,target_word,labels):\n",
    "    wic_padded=[]\n",
    "    for i in range(0,len(sentences1)):\n",
    "\n",
    "        #print(words[i])\n",
    "        #sentence = f\"[CLS] {sentences1[i]} [SEP] {sentences2[i]} [SEP]\"\n",
    "        sentence = f\"<s> {sentences1[i]}</s><s>{sentences2[i]}</s>\"\n",
    "        #print(sentence)\n",
    "        tokens=tokenizer(sentence, add_special_tokens=False,pad_to_max_length=True,\n",
    "                  truncation=True,max_length=512)\n",
    "        input_ids = tokens[\"input_ids\"]\n",
    "        attention_mask = tokens[\"attention_mask\"]\n",
    "        #print(input_ids)\n",
    "        target_word=words[i]\n",
    "        target_token = tokenizer.encode(target_word)\n",
    "        target_token=target_token[1:-1]\n",
    "        \n",
    "        sep_occurrences = [index for index, token_id in enumerate(input_ids) if token_id == tokenizer.sep_token_id]\n",
    "\n",
    "        #print(tokenizer.sep_token_id)\n",
    "        if len(sep_occurrences)!=0:\n",
    "            sep_index = sep_occurrences[0]\n",
    "\n",
    "            tokens_before_sep = input_ids[:sep_index]\n",
    "            tokens_after_sep = input_ids[sep_index + 1:]\n",
    "            #print(tokens_before_sep,tokens_after_sep)\n",
    "            is_present1= str(target_token).replace(\"[\",\"\").replace(\"]\",\"\") in str(tokens_before_sep)\n",
    "            is_present2= str(target_token).replace(\"[\",\"\").replace(\"]\",\"\") in str(tokens_after_sep)\n",
    "            #print(target_token)\n",
    "            #print(is_present1,is_present2)\n",
    "            if is_present1!=False and is_present2!=False:\n",
    "                target_word_ids_before_sep = find_indexes_before(tokens_before_sep,target_token)\n",
    "                target_word_ids_after_sep = find_indexes_after(tokens_after_sep,len(tokens_before_sep)-1,target_token)\n",
    "\n",
    "\n",
    "                mask_tensor_sent1 = torch.zeros_like(torch.tensor(input_ids))\n",
    "                mask_tensor_sent1[target_word_ids_before_sep] = 1\n",
    "                mask_tensor_sent2 = torch.zeros_like(torch.tensor(input_ids))\n",
    "                mask_tensor_sent2[target_word_ids_after_sep] = 1\n",
    "                sample_data = {\n",
    "                                \"input_ids\": torch.tensor(input_ids),\n",
    "                                \"attention_mask\": torch.tensor(attention_mask),\n",
    "                                \"word1_locs\": mask_tensor_sent1,\n",
    "                                \"word2_locs\": mask_tensor_sent2,\n",
    "                                \"labels\": torch.tensor(labels[i]),\n",
    "                                \"sentence\": sentence,\n",
    "                                \"target_word\":words[i]\n",
    "                            }\n",
    "\n",
    "                # Append the data for the current sample to the list\n",
    "                wic_padded.append(sample_data)\n",
    "    return wic_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-08T20:59:26.459384Z",
     "iopub.status.busy": "2023-08-08T20:59:26.459042Z",
     "iopub.status.idle": "2023-08-08T20:59:31.808203Z",
     "shell.execute_reply": "2023-08-08T20:59:31.806922Z",
     "shell.execute_reply.started": "2023-08-08T20:59:26.459358Z"
    },
    "id": "JDDDeuXsxvLm",
    "outputId": "e0294177-5c34-4aed-f6a6-ef66f1cee1de"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#create test dataset\n",
    "\n",
    "wic_test_set = create_data_set(sentences1,sentences2,words,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T21:00:25.413118Z",
     "iopub.status.busy": "2023-08-08T21:00:25.412771Z",
     "iopub.status.idle": "2023-08-08T21:00:25.456691Z",
     "shell.execute_reply": "2023-08-08T21:00:25.455787Z",
     "shell.execute_reply.started": "2023-08-08T21:00:25.413092Z"
    },
    "id": "MxYTqaLbxvLm"
   },
   "outputs": [],
   "source": [
    "test_data = TensorDataset(\n",
    "    torch.stack([sample[\"input_ids\"] for sample in wic_test_set]),\n",
    "    torch.stack([sample[\"attention_mask\"] for sample in wic_test_set]),\n",
    "    torch.stack([sample[\"word1_locs\"] for sample in wic_test_set]),\n",
    "    torch.stack([sample[\"word2_locs\"] for sample in wic_test_set]),\n",
    "    torch.stack([sample[\"labels\"] for sample in wic_test_set])\n",
    ")\n",
    "\n",
    "# Create a sampler and loader\n",
    "test_sampler = RandomSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-08T21:00:27.068388Z",
     "iopub.status.busy": "2023-08-08T21:00:27.067800Z",
     "iopub.status.idle": "2023-08-08T21:00:27.087649Z",
     "shell.execute_reply": "2023-08-08T21:00:27.086279Z",
     "shell.execute_reply.started": "2023-08-08T21:00:27.068303Z"
    },
    "id": "k_-B4fquxvLn",
    "outputId": "9a33b8a6-9000-44e4-ea1f-694451780129"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1930\n"
     ]
    }
   ],
   "source": [
    "print(len(wic_test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "execution": {
     "iopub.execute_input": "2023-08-08T05:45:21.641272Z",
     "iopub.status.busy": "2023-08-08T05:45:21.640363Z",
     "iopub.status.idle": "2023-08-08T05:45:22.528863Z",
     "shell.execute_reply": "2023-08-08T05:45:22.528195Z",
     "shell.execute_reply.started": "2023-08-08T05:45:21.641228Z"
    },
    "id": "KNwwj60kxvLn",
    "outputId": "9f075dfe-9407-43ee-a59b-cbbe53d5afd8"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-2dfe0f0e18fa>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#load weights of best model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'saved_weights_muril.pt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclass_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    792\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'saved_weights_muril.pt'"
     ]
    }
   ],
   "source": [
    "#load weights of best model\n",
    "path = 'saved_weights_muril.pt'\n",
    "class_model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-08T21:00:32.946658Z",
     "iopub.status.busy": "2023-08-08T21:00:32.946285Z",
     "iopub.status.idle": "2023-08-08T21:01:54.987417Z",
     "shell.execute_reply": "2023-08-08T21:01:54.986157Z",
     "shell.execute_reply.started": "2023-08-08T21:00:32.946658Z"
    },
    "id": "L5mDzeXmxvLn",
    "outputId": "567cfa15-9b72-43be-fda7-5327b2e22b96"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-d3ae0b3d8a91>:42: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  logits = self.softmax(self.linear_seperator(layer1_results))\n"
     ]
    }
   ],
   "source": [
    "# get predictions for test data\n",
    "class_model.eval()\n",
    "total_preds=[]\n",
    "test_labels1=[]\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        batch = [t.to(device) for t in batch]\n",
    "        test_ids, test_mask, test_word1, test_word2, test_labels = batch\n",
    "        _,logits = class_model(test_ids, test_mask, test_word1, test_word2, test_labels)\n",
    "        logits=logits.detach().cpu().numpy()\n",
    "        test_labels1.append(test_labels.detach().cpu().numpy())\n",
    "        #print(logits)\n",
    "        preds = np.argmax(logits, axis=1).flatten()\n",
    "        total_preds.append(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-08T21:24:45.131719Z",
     "iopub.status.busy": "2023-08-08T21:24:45.131219Z",
     "iopub.status.idle": "2023-08-08T21:24:45.139644Z",
     "shell.execute_reply": "2023-08-08T21:24:45.138179Z",
     "shell.execute_reply.started": "2023-08-08T21:24:45.131680Z"
    },
    "id": "tWdkKMJPxvLn",
    "outputId": "7eaec725-cd8d-4f5b-8700-0712526e72d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1930\n",
      "1930\n"
     ]
    }
   ],
   "source": [
    "total_preds1=[]\n",
    "for i in total_preds:\n",
    "    for i1 in i:\n",
    "        total_preds1.append(i1)\n",
    "\n",
    "print(len(total_preds1))\n",
    "\n",
    "test_labels2=[]\n",
    "for i in test_labels1:\n",
    "    for i1 in i:\n",
    "        test_labels2.append(i1)\n",
    "\n",
    "print(len(test_labels2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-08T21:24:46.722367Z",
     "iopub.status.busy": "2023-08-08T21:24:46.722022Z",
     "iopub.status.idle": "2023-08-08T21:24:46.737340Z",
     "shell.execute_reply": "2023-08-08T21:24:46.736393Z",
     "shell.execute_reply.started": "2023-08-08T21:24:46.722342Z"
    },
    "id": "0oXlkYm5xvLo",
    "outputId": "e57a4225-f107-4509-cb79-b90b4d181d76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.50      0.56      1094\n",
      "           1       0.49      0.63      0.55       836\n",
      "\n",
      "    accuracy                           0.56      1930\n",
      "   macro avg       0.57      0.57      0.56      1930\n",
      "weighted avg       0.58      0.56      0.56      1930\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model's performance\n",
    "#preds = np.argmax(preds, axis = 1)\n",
    "print(classification_report(test_labels2, total_preds1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q3sQB3ezxvLo"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0338d6144d764f198ac61ee8c9e9bdf9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0a3f8f8c15b6494b8ddbcdd4fe996ebe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f163fdef65d24fb7bcec80d6bde4b669",
      "max": 1115567652,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2f055de872e14133b294c7c36a2a5b77",
      "value": 1115567652
     }
    },
    "11d25617b73e458fb203e270eaab250f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1285ba33c84e433ebb7bad7c65a7786b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_18eb570aedd54c25b639ae20ed6a7dd4",
       "IPY_MODEL_63a2b01df7de467982dddb133172ae00",
       "IPY_MODEL_45515774e49e4c31bffffbacbe50da7e"
      ],
      "layout": "IPY_MODEL_541a6ef8a939449394bb44b502a3e565"
     }
    },
    "18eb570aedd54c25b639ae20ed6a7dd4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f75049eac5534077a819d7ed2cdcf941",
      "placeholder": "​",
      "style": "IPY_MODEL_da97aa5771d94756b154fb4faea61c1a",
      "value": "Downloading (…)lve/main/config.json: 100%"
     }
    },
    "22c1cc728c2b41d4898933121c9f2fe8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d642308d57f443828c7de94a8e73a126",
      "placeholder": "​",
      "style": "IPY_MODEL_0338d6144d764f198ac61ee8c9e9bdf9",
      "value": "Downloading (…)tencepiece.bpe.model: 100%"
     }
    },
    "2f055de872e14133b294c7c36a2a5b77": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "39d7b26d0e92491a9600ae42a31cdf68": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4507b375f0934e6da8fe176ec4c8661e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "45515774e49e4c31bffffbacbe50da7e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b94c72ce11d342c4b2857b60c87b6d54",
      "placeholder": "​",
      "style": "IPY_MODEL_11d25617b73e458fb203e270eaab250f",
      "value": " 615/615 [00:00&lt;00:00, 49.0kB/s]"
     }
    },
    "481a6d719ee74937bc8fe6800194a12f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4b3b8d95f17642c1bed815e97f0e14f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_22c1cc728c2b41d4898933121c9f2fe8",
       "IPY_MODEL_cb98d29d981148a3b5c494fbee3eb92a",
       "IPY_MODEL_5e5601f8691249bd9480c456f9e354ab"
      ],
      "layout": "IPY_MODEL_b5bc9cf4a1a34412b318fe9084d0a779"
     }
    },
    "52686a3a893b47c4b95485e9f45dc685": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6d4c66d9847e421c80b10cfffe940aec",
      "placeholder": "​",
      "style": "IPY_MODEL_39d7b26d0e92491a9600ae42a31cdf68",
      "value": " 1.12G/1.12G [00:04&lt;00:00, 253MB/s]"
     }
    },
    "541a6ef8a939449394bb44b502a3e565": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5e5601f8691249bd9480c456f9e354ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_616def7743554c3c893c45d66c9f20f4",
      "placeholder": "​",
      "style": "IPY_MODEL_d8b3f21a5d3a4acf855e46836ca48751",
      "value": " 5.07M/5.07M [00:01&lt;00:00, 5.00MB/s]"
     }
    },
    "616def7743554c3c893c45d66c9f20f4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "63a2b01df7de467982dddb133172ae00": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fafd13f82f0c4aa2934b266915721516",
      "max": 615,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c94d9f4f0c4a458eb998d1a44687a334",
      "value": 615
     }
    },
    "67635a8a2ea2490b875c775a15850707": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6d4c66d9847e421c80b10cfffe940aec": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7ee4abd09365479db3b86cc2106de9e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e9109ee6f7a8414d8450169413e3f281",
       "IPY_MODEL_0a3f8f8c15b6494b8ddbcdd4fe996ebe",
       "IPY_MODEL_52686a3a893b47c4b95485e9f45dc685"
      ],
      "layout": "IPY_MODEL_a10959b28e7642588741b0e9f344ecb2"
     }
    },
    "8e8b67e3684c437c9d2e6e0a4b2a8ab5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e064157216534f3bab41eb8d7e6b82eb",
       "IPY_MODEL_d162fb82de114ddaa71c051aa8fef1ed",
       "IPY_MODEL_f4932b80fe724bda8d493c0eba9d8a28"
      ],
      "layout": "IPY_MODEL_db49a123f6764db1a89db7973e48c40e"
     }
    },
    "90c6de5ce888439d90ddf9ab740d81e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9d7222be685741328e7fd332fb615b15": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a05021b7ad3748ca852d7900e19e328e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a10959b28e7642588741b0e9f344ecb2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b5bc9cf4a1a34412b318fe9084d0a779": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b94c72ce11d342c4b2857b60c87b6d54": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "baee3fcb5d504e209bb9b28733a69554": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c94d9f4f0c4a458eb998d1a44687a334": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cb98d29d981148a3b5c494fbee3eb92a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_481a6d719ee74937bc8fe6800194a12f",
      "max": 5069051,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_67635a8a2ea2490b875c775a15850707",
      "value": 5069051
     }
    },
    "d162fb82de114ddaa71c051aa8fef1ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e971ac16ad4d4bc0b8eda6c25c9a04a2",
      "max": 9096718,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a05021b7ad3748ca852d7900e19e328e",
      "value": 9096718
     }
    },
    "d642308d57f443828c7de94a8e73a126": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d8b3f21a5d3a4acf855e46836ca48751": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "da97aa5771d94756b154fb4faea61c1a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "db49a123f6764db1a89db7973e48c40e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e064157216534f3bab41eb8d7e6b82eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ee41a4d3be2a4b07914add6d0c70e562",
      "placeholder": "​",
      "style": "IPY_MODEL_e335c757e5454cab8f68ccfc722bbfee",
      "value": "Downloading (…)/main/tokenizer.json: 100%"
     }
    },
    "e335c757e5454cab8f68ccfc722bbfee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e9109ee6f7a8414d8450169413e3f281": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9d7222be685741328e7fd332fb615b15",
      "placeholder": "​",
      "style": "IPY_MODEL_90c6de5ce888439d90ddf9ab740d81e0",
      "value": "Downloading model.safetensors: 100%"
     }
    },
    "e971ac16ad4d4bc0b8eda6c25c9a04a2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ee41a4d3be2a4b07914add6d0c70e562": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f163fdef65d24fb7bcec80d6bde4b669": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f4932b80fe724bda8d493c0eba9d8a28": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_baee3fcb5d504e209bb9b28733a69554",
      "placeholder": "​",
      "style": "IPY_MODEL_4507b375f0934e6da8fe176ec4c8661e",
      "value": " 9.10M/9.10M [00:00&lt;00:00, 16.9MB/s]"
     }
    },
    "f75049eac5534077a819d7ed2cdcf941": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fafd13f82f0c4aa2934b266915721516": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
