{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z8d__AnekbS_"
   },
   "source": [
    "## Choose Devise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-24T03:13:17.168616Z",
     "iopub.status.busy": "2023-08-24T03:13:17.167701Z",
     "iopub.status.idle": "2023-08-24T03:13:18.294977Z",
     "shell.execute_reply": "2023-08-24T03:13:18.291613Z",
     "shell.execute_reply.started": "2023-08-24T03:13:17.168616Z"
    },
    "id": "o0kJUuJYkbTC",
    "outputId": "857b8321-63ff-443f-957b-315f25dc5b07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Quadro P5000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():\n",
    "\n",
    "    # Tell PyTorch to use the GPU.\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yPEzxrx9kbTE"
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-24T03:13:18.297374Z",
     "iopub.status.busy": "2023-08-24T03:13:18.296981Z",
     "iopub.status.idle": "2023-08-24T03:13:24.708541Z",
     "shell.execute_reply": "2023-08-24T03:13:24.706938Z",
     "shell.execute_reply.started": "2023-08-24T03:13:18.297318Z"
    },
    "id": "rNj6bImykbTE",
    "outputId": "08f59367-f0a5-4346-b089-2334d0c9be4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-transformers\n",
      "  Downloading pytorch_transformers-1.2.0-py3-none-any.whl (176 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.4/176.4 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from pytorch-transformers) (4.64.1)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.9/dist-packages (from pytorch-transformers) (1.24.90)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.9/dist-packages (from pytorch-transformers) (0.1.97)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from pytorch-transformers) (1.12.1+cu116)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from pytorch-transformers) (2.28.2)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.9/dist-packages (from pytorch-transformers) (2022.10.31)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from pytorch-transformers) (1.23.4)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.0.0->pytorch-transformers) (4.4.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.9/dist-packages (from boto3->pytorch-transformers) (1.0.1)\n",
      "Requirement already satisfied: botocore<1.28.0,>=1.27.90 in /usr/local/lib/python3.9/dist-packages (from boto3->pytorch-transformers) (1.27.90)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from boto3->pytorch-transformers) (0.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests->pytorch-transformers) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->pytorch-transformers) (2019.11.28)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->pytorch-transformers) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->pytorch-transformers) (1.26.14)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from sacremoses->pytorch-transformers) (1.14.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from sacremoses->pytorch-transformers) (8.1.3)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from sacremoses->pytorch-transformers) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.9/dist-packages (from botocore<1.28.0,>=1.27.90->boto3->pytorch-transformers) (2.8.2)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895242 sha256=407e8682f448cb3a71f78aceb2d05db0a26c4d358c6d3c373b1053e1e2fabf51\n",
      "  Stored in directory: /root/.cache/pip/wheels/42/79/78/5ad3b042cb2d97c294535162cdbaf9b167e3b186eae55ab72d\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: sacremoses, pytorch-transformers\n",
      "Successfully installed pytorch-transformers-1.2.0 sacremoses-0.0.53\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pytorch-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-24T03:13:24.712504Z",
     "iopub.status.busy": "2023-08-24T03:13:24.711473Z",
     "iopub.status.idle": "2023-08-24T03:13:28.975680Z",
     "shell.execute_reply": "2023-08-24T03:13:28.975010Z",
     "shell.execute_reply.started": "2023-08-24T03:13:24.712504Z"
    },
    "id": "ripr3Mp-kbTE",
    "outputId": "0ce3c49b-bd81-4ea1-dad7-36ad6b359450"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.21.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.28.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.12.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.23.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers) (2019.11.28)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers) (2.8)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-24T03:13:28.978099Z",
     "iopub.status.busy": "2023-08-24T03:13:28.977743Z",
     "iopub.status.idle": "2023-08-24T03:13:30.493715Z",
     "shell.execute_reply": "2023-08-24T03:13:30.491668Z",
     "shell.execute_reply.started": "2023-08-24T03:13:28.978052Z"
    },
    "id": "Bg4PWJP0kbTF"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import string\n",
    "import copy\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from sklearn.metrics import classification_report\n",
    "from pytorch_transformers import *\n",
    "import numpy as np\n",
    "import json\n",
    "import collections\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-24T03:13:30.497716Z",
     "iopub.status.busy": "2023-08-24T03:13:30.496353Z",
     "iopub.status.idle": "2023-08-24T03:13:30.501913Z",
     "shell.execute_reply": "2023-08-24T03:13:30.501723Z",
     "shell.execute_reply.started": "2023-08-24T03:13:30.497716Z"
    },
    "id": "Op6yJevRkbTF"
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OYn-_I7QkbTF"
   },
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-24T03:13:30.505031Z",
     "iopub.status.busy": "2023-08-24T03:13:30.505031Z",
     "iopub.status.idle": "2023-08-24T03:13:30.723710Z",
     "shell.execute_reply": "2023-08-24T03:13:30.721308Z",
     "shell.execute_reply.started": "2023-08-24T03:13:30.505031Z"
    },
    "id": "TbyUoYBikbTF",
    "outputId": "825f74b8-95f3-4c32-fcd6-2bfec9b514ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training sentences: 7,000\n",
      "\n",
      "(7000, 9)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset into a pandas dataframe.\n",
    "df = pd.read_csv(\"hindi-wsd_train.csv\")\n",
    "\n",
    "# Report the number of sentences.\n",
    "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
    "\n",
    "# Display 10 random rows from the data.\n",
    "# df.sample(10)\n",
    "df1 = df\n",
    "print(df1.shape)\n",
    "#Labels - 1 for True and 0 for False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 536
    },
    "execution": {
     "iopub.execute_input": "2023-08-24T03:13:30.724454Z",
     "iopub.status.busy": "2023-08-24T03:13:30.724140Z",
     "iopub.status.idle": "2023-08-24T03:13:30.746670Z",
     "shell.execute_reply": "2023-08-24T03:13:30.745342Z",
     "shell.execute_reply.started": "2023-08-24T03:13:30.724447Z"
    },
    "id": "zUPJiu5BkbTG",
    "outputId": "6cb32716-92e4-4cc0-a0e9-683ab36e0bb2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_word</th>\n",
       "      <th>word_index</th>\n",
       "      <th>context_instance1</th>\n",
       "      <th>context_instance2</th>\n",
       "      <th>start1</th>\n",
       "      <th>end1</th>\n",
       "      <th>start2</th>\n",
       "      <th>end2</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>कलम</td>\n",
       "      <td>8</td>\n",
       "      <td>इसमें पहली बार बालक के सिर और कलम के बाल उतार...</td>\n",
       "      <td>इसलिए साहित्यकार को सरकार के समाजवादी कार्यक्...</td>\n",
       "      <td>391</td>\n",
       "      <td>34</td>\n",
       "      <td>279</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>कांड</td>\n",
       "      <td>9</td>\n",
       "      <td>दूसरे दिन पुलिस ने इस हत्या कांड के सिलसिले म...</td>\n",
       "      <td>भानुभक्त कृत रामायण की कथा अध्यात्म रामायण पर...</td>\n",
       "      <td>482</td>\n",
       "      <td>224</td>\n",
       "      <td>348</td>\n",
       "      <td>156</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>अंग</td>\n",
       "      <td>1</td>\n",
       "      <td>इनमें बैंकों की परम्पराओं का भी निर्वाह किया ...</td>\n",
       "      <td>हाथ के किसी उपकरण (औजार) से किसी चीज को इच्छि...</td>\n",
       "      <td>453</td>\n",
       "      <td>346</td>\n",
       "      <td>571</td>\n",
       "      <td>333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>खान</td>\n",
       "      <td>14</td>\n",
       "      <td>जयपुर. गुरु पूर्णिमा महोत्सव के तहत अमरूदों क...</td>\n",
       "      <td>माय नेम इज खान  फिल्म कैसी बनी है? अभी किसी भ...</td>\n",
       "      <td>601</td>\n",
       "      <td>283</td>\n",
       "      <td>709</td>\n",
       "      <td>243</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>अंग</td>\n",
       "      <td>1</td>\n",
       "      <td>छवि कलाकारी को एक विशेष रूप सुंग काल में दिया...</td>\n",
       "      <td>जनवरीमें समस्त वाणिज्य बैंकों को सूचित किया ग...</td>\n",
       "      <td>813</td>\n",
       "      <td>800</td>\n",
       "      <td>406</td>\n",
       "      <td>198</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>दर</td>\n",
       "      <td>38</td>\n",
       "      <td>शलभ भी प्राय: रात के समय निकलते हैं इनका एक ज...</td>\n",
       "      <td>इराक़ बारबार कहता आया है कि वह हथियार निरीक्ष...</td>\n",
       "      <td>531</td>\n",
       "      <td>455</td>\n",
       "      <td>581</td>\n",
       "      <td>566</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>गुरु</td>\n",
       "      <td>17</td>\n",
       "      <td>लेकिन कहीं न कहीं उनकी बुराइयों की जड़ में राज...</td>\n",
       "      <td>गुरु मंत्र का जाप करना गुरु की शुभता प्राप्त ...</td>\n",
       "      <td>476</td>\n",
       "      <td>348</td>\n",
       "      <td>360</td>\n",
       "      <td>224</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>जीना</td>\n",
       "      <td>24</td>\n",
       "      <td>यदि सीढ़ियाँ चक्राकार सर्पिल हों तो 'ची' ऊर्जा...</td>\n",
       "      <td>पिछले सप्ताह एक के बाद एक तीन निकट सम्बन्धियो...</td>\n",
       "      <td>423</td>\n",
       "      <td>230</td>\n",
       "      <td>623</td>\n",
       "      <td>521</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>कलम</td>\n",
       "      <td>8</td>\n",
       "      <td>इसलिए साहित्यकार को सरकार के समाजवादी कार्यक्...</td>\n",
       "      <td>एक गुच्छा दूसरे से भिन्न होता है यदि एक मीटर ...</td>\n",
       "      <td>279</td>\n",
       "      <td>169</td>\n",
       "      <td>549</td>\n",
       "      <td>297</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>कुंभ</td>\n",
       "      <td>10</td>\n",
       "      <td>उनका कार्यक्षेत्र और कार्य करने की परिसीमा कु...</td>\n",
       "      <td>जब हम सनमें नासिक रहने के लिये आये तब ये शहरम...</td>\n",
       "      <td>326</td>\n",
       "      <td>236</td>\n",
       "      <td>502</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target_word  word_index                                  context_instance1  \\\n",
       "0         कलम           8   इसमें पहली बार बालक के सिर और कलम के बाल उतार...   \n",
       "1        कांड           9   दूसरे दिन पुलिस ने इस हत्या कांड के सिलसिले म...   \n",
       "2         अंग           1   इनमें बैंकों की परम्पराओं का भी निर्वाह किया ...   \n",
       "3         खान          14   जयपुर. गुरु पूर्णिमा महोत्सव के तहत अमरूदों क...   \n",
       "4         अंग           1   छवि कलाकारी को एक विशेष रूप सुंग काल में दिया...   \n",
       "5          दर          38   शलभ भी प्राय: रात के समय निकलते हैं इनका एक ज...   \n",
       "6        गुरु          17   लेकिन कहीं न कहीं उनकी बुराइयों की जड़ में राज...   \n",
       "7        जीना          24   यदि सीढ़ियाँ चक्राकार सर्पिल हों तो 'ची' ऊर्जा...   \n",
       "8         कलम           8   इसलिए साहित्यकार को सरकार के समाजवादी कार्यक्...   \n",
       "9        कुंभ          10   उनका कार्यक्षेत्र और कार्य करने की परिसीमा कु...   \n",
       "\n",
       "                                   context_instance2 start1 end1 start2 end2  \\\n",
       "0   इसलिए साहित्यकार को सरकार के समाजवादी कार्यक्...    391   34    279  169   \n",
       "1   भानुभक्त कृत रामायण की कथा अध्यात्म रामायण पर...    482  224    348  156   \n",
       "2   हाथ के किसी उपकरण (औजार) से किसी चीज को इच्छि...    453  346    571  333   \n",
       "3   माय नेम इज खान  फिल्म कैसी बनी है? अभी किसी भ...    601  283    709  243   \n",
       "4   जनवरीमें समस्त वाणिज्य बैंकों को सूचित किया ग...    813  800    406  198   \n",
       "5   इराक़ बारबार कहता आया है कि वह हथियार निरीक्ष...    531  455    581  566   \n",
       "6   गुरु मंत्र का जाप करना गुरु की शुभता प्राप्त ...    476  348    360  224   \n",
       "7   पिछले सप्ताह एक के बाद एक तीन निकट सम्बन्धियो...    423  230    623  521   \n",
       "8   एक गुच्छा दूसरे से भिन्न होता है यदि एक मीटर ...    279  169    549  297   \n",
       "9   जब हम सनमें नासिक रहने के लिये आये तब ये शहरम...    326  236    502   68   \n",
       "\n",
       "   labels  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  \n",
       "5       0  \n",
       "6       0  \n",
       "7       0  \n",
       "8       0  \n",
       "9       0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-24T03:13:30.748480Z",
     "iopub.status.busy": "2023-08-24T03:13:30.748400Z",
     "iopub.status.idle": "2023-08-24T03:13:30.758135Z",
     "shell.execute_reply": "2023-08-24T03:13:30.757130Z",
     "shell.execute_reply.started": "2023-08-24T03:13:30.748454Z"
    },
    "id": "bv-7AOjrkbTG",
    "outputId": "e19fd3da-f4fe-484b-cb0f-97df25472c92"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.5\n",
       "1    0.5\n",
       "Name: labels, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check class distribution\n",
    "df['labels'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-24T03:13:30.759491Z",
     "iopub.status.busy": "2023-08-24T03:13:30.759229Z",
     "iopub.status.idle": "2023-08-24T03:13:30.767130Z",
     "shell.execute_reply": "2023-08-24T03:13:30.766388Z",
     "shell.execute_reply.started": "2023-08-24T03:13:30.759471Z"
    },
    "id": "Li8VOctIkbTG"
   },
   "outputs": [],
   "source": [
    "sentences1= df1.context_instance1.values\n",
    "sentences2= df1.context_instance2.values\n",
    "words= df1.target_word.values\n",
    "labels = df1.labels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "execution": {
     "iopub.execute_input": "2023-08-24T03:13:30.769742Z",
     "iopub.status.busy": "2023-08-24T03:13:30.768254Z",
     "iopub.status.idle": "2023-08-24T03:13:31.870555Z",
     "shell.execute_reply": "2023-08-24T03:13:31.869738Z",
     "shell.execute_reply.started": "2023-08-24T03:13:30.769742Z"
    },
    "id": "lkUQXnDnkbTG",
    "outputId": "fc5fb064-8acc-4be8-cff8-ef792677251a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get length of all the sentences\n",
    "seq_len = [len(i) for i in sentences1]\n",
    "\n",
    "pd.Series(seq_len).hist(bins = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VWwQm1K4kbTG"
   },
   "source": [
    "## Import Model & Model Tokenizer | Model Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "67E5Y5xzuexb"
   },
   "source": [
    "### List of models present in the experiment:\n",
    "The below models specified were used for the purpose to understand how the models perform when trained and tested on the Hindi Language:\n",
    "\n",
    "\n",
    "* xlm-roberta-base\n",
    "\n",
    "Please remove the # character to run the chosen model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 130,
     "referenced_widgets": [
      "933dc18174704aec8c63b9c4072bf98e",
      "5b3aa69346004acf89fc95e55455f834",
      "9d07260e677e4837b8b1be3236868f3a",
      "fabb8edac60d42de9615dd695f20b6ca",
      "0195c1e570bc4a50ac6a76398a602f74",
      "b561c3ee2c64492e85a5d8e582c1d8d3",
      "464247999a2a4eb2947c9cfcbbcb3bb2",
      "0a48e13d5e2543468a0e7245df6b00a3",
      "5719f09b75bb48ffbcf0a63f85a3172e",
      "2e98110b1a9b43c7a8edd80dcd2e4f25",
      "fe4e419805e547b28863c46c92e0ba7a",
      "3417e52af80a46a586683ef0e6c4fbf1",
      "85370c62279440218d38e8acd255fc05",
      "3d8b6932bf7a44c2a1c00ddcf58906ab",
      "cd0468c7826b46edaa3ab1c3867f6234",
      "aaae3d763d89466a952716c22e9fe157",
      "58edc1b0da10479a865169bb94ce5c2c",
      "8d8bddd9c74d4a05a6892baab0dc7c03",
      "8cdfb7f5e335423b8e04f30d125c1020",
      "3a73060d1212478eaf177b22c0069f42",
      "329d2bd7f16f4c5280d9b6abd428129b",
      "a6f4d19f3c58466da90b6d1f0e22554c",
      "fcd03a1f863c42fd82963fc7f063ac14",
      "7b0d969ae56948d1b0fc798ad8c2e284",
      "ef0d749846764aeab947cad9ab2c018a",
      "6d747f4319894c9480932bc234ac7881",
      "7765ee2eec294caab60b7a41b7569920",
      "bc999e1445c2427481877d9bbfc46f5d",
      "745f2c8fd1a54a6cb0dce5e6cd86b0ed",
      "5d82cae64a7e47328834ecacaca9bbee",
      "083979ceec0146fba79b86a788e32c26",
      "0a6bdd7b86a54034ba2cf7b38dcfbafe",
      "9c148419416e4a30a4c28da6e34498a2"
     ]
    },
    "execution": {
     "iopub.execute_input": "2023-08-24T03:13:31.875620Z",
     "iopub.status.busy": "2023-08-24T03:13:31.874901Z",
     "iopub.status.idle": "2023-08-24T03:13:36.688818Z",
     "shell.execute_reply": "2023-08-24T03:13:36.687265Z",
     "shell.execute_reply.started": "2023-08-24T03:13:31.875575Z"
    },
    "id": "3N1qajjykbTH",
    "outputId": "977c7bb9-d0dd-4539-e0f8-8720bc7ed5f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xlm-roberta-base\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6de5e399a9ca4818a5e6732b5516e115",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d11e005f75d47599ecb5eccac31d47a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading sentencepiece.bpe.model:   0%|          | 0.00/4.83M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b80342b6c46546258233aa21ee324054",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/8.68M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n",
    "model_name='xlm-roberta-base'\n",
    "print(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867,
     "referenced_widgets": [
      "1052e793352d457083d5ec3c5986a584",
      "8a0d3551c04e4d3aac5b5e73920f7c74",
      "704a7ca3dc5d407cbbb85ec79b67bfd0",
      "c3b8572c6f894f5ba8194a15936dd864",
      "162bc9a75cce47cab9bb1cc1f78fb46c",
      "346bcab017db4ff7acd59fc6fa17059e",
      "a259f3ee14124962ac71a50689e4be52",
      "14293f95fb4242718956cc9715184120",
      "86194656e8b44b9a82a0530ceb51251b",
      "791907143a374b558311e58f958ad6a6",
      "2f70e3de77cd40c19a5aeda82ebc520f"
     ]
    },
    "execution": {
     "iopub.execute_input": "2023-08-24T03:13:36.690785Z",
     "iopub.status.busy": "2023-08-24T03:13:36.690158Z",
     "iopub.status.idle": "2023-08-24T03:14:02.620808Z",
     "shell.execute_reply": "2023-08-24T03:14:02.620131Z",
     "shell.execute_reply.started": "2023-08-24T03:13:36.690742Z"
    },
    "id": "PTgHsPvJkbTH",
    "outputId": "1a0d8901-a459-47ff-87f3-43c2d3772b65"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "005067ecf1444f019a60c7047b376ed8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.04G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XLMRobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
    "    # output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = True, # Whether the model returns all hidden-states.\n",
    ")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C6IkWP5ekbTH"
   },
   "source": [
    "## Create Train Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "27OuI6I-kbTH"
   },
   "source": [
    "The below functions will find the range of indexes of the target words from the two context sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-24T03:20:03.851903Z",
     "iopub.status.busy": "2023-08-24T03:20:03.850562Z",
     "iopub.status.idle": "2023-08-24T03:20:03.862043Z",
     "shell.execute_reply": "2023-08-24T03:20:03.860523Z",
     "shell.execute_reply.started": "2023-08-24T03:20:03.851815Z"
    },
    "id": "IPHphKSRkbTH"
   },
   "outputs": [],
   "source": [
    "def find_indexes_before(list1, list2):\n",
    "    index = 0\n",
    "    while index <= len(list1) - len(list2):\n",
    "        if list1[index:index + len(list2)] == list2:\n",
    "            return list(range(index, index + len(list2)))\n",
    "        index += 1\n",
    "    return []\n",
    "\n",
    "def find_indexes_after(list1, before_length,list2):\n",
    "    index = 0\n",
    "    while index <= len(list1) - len(list2):\n",
    "        if list1[index:index + len(list2)] == list2:\n",
    "            #print(index)\n",
    "            return list(range(index +before_length, index +before_length +  len(list2)))\n",
    "        index += 1\n",
    "    return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N1prsPmjkbTH"
   },
   "source": [
    "The below function creates the dataset in the required format that is it contains a dictionary of lists with:\n",
    "1. Input IDs -  sequence of integer tokens that represent the input text. Each token in the text is mapped to a unique integer ID based on a tokenizer. BERT uses a fixed-size vocabulary, and each token in the text is converted to its corresponding ID from the vocabulary.\n",
    "\n",
    "2. Attention mask - binary mask tensor that indicates which tokens in the input should be attended to (receive attention) and which tokens should be ignored. It is used to handle variable-length input sequences. The mask has the same length as the input sequence and contains 0s and 1s\n",
    "\n",
    "3. Target Word Location in sentence 1 - used to extract embeddings of target word from sentence 1\n",
    "\n",
    "4. Target Word Location in sentence 2 - used to extract embeddings of target word from sentence 2\n",
    "\n",
    "5. Labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-24T03:21:44.492835Z",
     "iopub.status.busy": "2023-08-24T03:21:44.491871Z",
     "iopub.status.idle": "2023-08-24T03:21:44.506246Z",
     "shell.execute_reply": "2023-08-24T03:21:44.503611Z",
     "shell.execute_reply.started": "2023-08-24T03:21:44.492803Z"
    },
    "id": "5ZUo1N7bkbTI"
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_data_set(sentences1,sentences2,words,labels):\n",
    "    wic_padded=[]\n",
    "    for i in range(0,len(sentences1)):\n",
    "\n",
    "        #print(words[i])\n",
    "        sentence = f\"<s> {sentences1[i]}</s><s>{sentences2[i]}</s>\"\n",
    "        #print(sentence)\n",
    "        tokens=tokenizer(sentence, add_special_tokens=False,pad_to_max_length=True,\n",
    "                  truncation=True,max_length=512)\n",
    "        input_ids = tokens[\"input_ids\"]\n",
    "        attention_mask = tokens[\"attention_mask\"]\n",
    "        #print(input_ids)\n",
    "        target_word=words[i]\n",
    "        target_token = tokenizer.encode(target_word)\n",
    "        target_token=target_token[1:-1]\n",
    "        #if running code for xlm roberta base\n",
    "        s_token_index = tokenizer.convert_tokens_to_ids('</s>')\n",
    "        sep_occurrences = [index for index, token_id in enumerate(input_ids) if token_id == s_token_index]\n",
    "\n",
    "        #print(sep_occurrences)\n",
    "        #break\n",
    "        if len(sep_occurrences)!=0:\n",
    "            sep_index = sep_occurrences[0]\n",
    "            #print(sep_index)\n",
    "            tokens_before_sep = input_ids[:sep_index]\n",
    "            tokens_after_sep = input_ids[sep_index + 1:]\n",
    "            #print(tokens_before_sep,tokens_after_sep)\n",
    "            is_present1= str(target_token).replace(\"[\",\"\").replace(\"]\",\"\") in str(tokens_before_sep)\n",
    "            is_present2= str(target_token).replace(\"[\",\"\").replace(\"]\",\"\") in str(tokens_after_sep)\n",
    "            #print(target_token)\n",
    "            #print(is_present1,is_present2)\n",
    "\n",
    "            if is_present1!=False and is_present2!=False:\n",
    "                #print(is_present1,is_present2)\n",
    "                target_word_ids_before_sep = find_indexes_before(tokens_before_sep,target_token)\n",
    "                target_word_ids_after_sep = find_indexes_after(tokens_after_sep,len(tokens_before_sep)-1,target_token)\n",
    "\n",
    "\n",
    "                mask_tensor_sent1 = torch.zeros_like(torch.tensor(input_ids))\n",
    "                mask_tensor_sent1[target_word_ids_before_sep] = 1\n",
    "                mask_tensor_sent2 = torch.zeros_like(torch.tensor(input_ids))\n",
    "                mask_tensor_sent2[target_word_ids_after_sep] = 1\n",
    "                sample_data = {\n",
    "                                \"input_ids\": torch.tensor(input_ids),\n",
    "                                \"attention_mask\": torch.tensor(attention_mask),\n",
    "                                \"word1_locs\": mask_tensor_sent1,\n",
    "                                \"word2_locs\": mask_tensor_sent2,\n",
    "                                \"labels\": torch.tensor(labels[i]),\n",
    "                                \"sentence\": sentence,\n",
    "                                \"target_word\":words[i]\n",
    "                            }\n",
    "            #break\n",
    "                # Append the data for the current sample to the list\n",
    "                wic_padded.append(sample_data)\n",
    "                # wic_padded[\"input_ids\"].append(torch.tensor(input_ids))\n",
    "                # wic_padded[\"attention_mask\"].append(torch.tensor(attention_mask))\n",
    "                # wic_padded[\"word1_locs\"].append(mask_tensor_sent1)\n",
    "                # wic_padded[\"word2_locs\"].append(mask_tensor_sent2)\n",
    "                # wic_padded[\"labels\"].append(labels[i])\n",
    "    return wic_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-24T03:21:45.573978Z",
     "iopub.status.busy": "2023-08-24T03:21:45.572514Z",
     "iopub.status.idle": "2023-08-24T03:22:00.099634Z",
     "shell.execute_reply": "2023-08-24T03:22:00.098369Z",
     "shell.execute_reply.started": "2023-08-24T03:21:45.573978Z"
    },
    "id": "dAIgVFOfkbTJ",
    "outputId": "10398c2a-3609-4cc3-8741-5ca1e43e0e69"
   },
   "outputs": [],
   "source": [
    "#create training dataset\n",
    "wic_train_set = create_data_set(sentences1,sentences2,words,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-24T03:22:00.101926Z",
     "iopub.status.busy": "2023-08-24T03:22:00.101551Z",
     "iopub.status.idle": "2023-08-24T03:22:00.108358Z",
     "shell.execute_reply": "2023-08-24T03:22:00.107148Z",
     "shell.execute_reply.started": "2023-08-24T03:22:00.101885Z"
    },
    "id": "chug984nkbTJ",
    "outputId": "d9d734e3-8909-41f9-cb39-ffce22e07bcb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6708\n"
     ]
    }
   ],
   "source": [
    "print(len(wic_train_set))\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-24T03:22:00.111402Z",
     "iopub.status.busy": "2023-08-24T03:22:00.110032Z",
     "iopub.status.idle": "2023-08-24T03:22:00.135561Z",
     "shell.execute_reply": "2023-08-24T03:22:00.134035Z",
     "shell.execute_reply.started": "2023-08-24T03:22:00.111402Z"
    },
    "id": "vXGb6M-PkbTJ"
   },
   "outputs": [],
   "source": [
    "train_labels=[]\n",
    "for i in wic_train_set:\n",
    "    x=i[\"labels\"].item()\n",
    "    train_labels.append(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-24T03:22:00.138155Z",
     "iopub.status.busy": "2023-08-24T03:22:00.137635Z",
     "iopub.status.idle": "2023-08-24T03:22:00.144289Z",
     "shell.execute_reply": "2023-08-24T03:22:00.143642Z",
     "shell.execute_reply.started": "2023-08-24T03:22:00.138126Z"
    },
    "id": "wyJyEowNkbTJ",
    "outputId": "98566e40-a850-441a-f9de-526d80e780b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6708\n"
     ]
    }
   ],
   "source": [
    "print(len(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-09T01:40:45.778634Z",
     "iopub.status.busy": "2023-08-09T01:40:45.778402Z",
     "iopub.status.idle": "2023-08-09T01:40:45.789595Z",
     "shell.execute_reply": "2023-08-09T01:40:45.788771Z",
     "shell.execute_reply.started": "2023-08-09T01:40:45.778612Z"
    },
    "id": "eYgaSKOOkbTJ",
    "outputId": "243e217d-11ac-46d1-a764-5727673a7618"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence:  <s>  इसमें पहली बार बालक के सिर और कलम के बाल उतारे जाते हैं यह कार्य जन्म से एक वर्ष या तीन वर्ष बाद या परिवार की परंपरा के आधार पर और बाद में हो सकता है चरक का विचार है कि केश श्मश्रु एवं नखों के काटने एवं प्रसाधन से पौष्टिकता बल आयुष्य शुचिता और सौंदर्य की प्राप्ति होती है इस संस्कार के पीछे स्वास्थ्य एवं सौंदर्य की भावना ही प्रमुख थी पहले यह घर पर होता था किंतु बाद में देवालयों में </s><s> इसलिए साहित्यकार को सरकार के समाजवादी कार्यक्रम में शामिल होने का पूरा हक है मगर सरकार समाजवादी हो तभी अन्यथा नहीं साहित्यकार को यथास्तिथि को तोड़ना है वह इस काम को कलम से तो करेगा ही जुलूस मेंसभा मेंशामिल होकर भीमत व्यक्त करके भी सही को प्रस्तुत करना उसका कर्त्तव्य हो जाता है</s>\n",
      "target_word:  कलम\n",
      "word1 location:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "word2 location:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "for i in wic_train_set:\n",
    "    x=i[\"word1_locs\"]\n",
    "    y=i[\"word2_locs\"]\n",
    "    print(\"sentence: \",i[\"sentence\"])\n",
    "    print(\"target_word: \",i[\"target_word\"])\n",
    "    print(\"word1 location: \",x)\n",
    "    print(\"word2 location: \",y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-09T01:40:45.797633Z",
     "iopub.status.busy": "2023-08-09T01:40:45.797399Z",
     "iopub.status.idle": "2023-08-09T01:40:45.803483Z",
     "shell.execute_reply": "2023-08-09T01:40:45.802187Z",
     "shell.execute_reply.started": "2023-08-09T01:40:45.797610Z"
    },
    "id": "h-dul0HekbTK",
    "outputId": "2db15623-5bff-41f0-e837-8e852b55ca07"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6708"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wic_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-24T03:30:54.830492Z",
     "iopub.status.busy": "2023-08-24T03:30:54.829897Z",
     "iopub.status.idle": "2023-08-24T03:30:54.933821Z",
     "shell.execute_reply": "2023-08-24T03:30:54.931208Z",
     "shell.execute_reply.started": "2023-08-24T03:30:54.830446Z"
    },
    "id": "uVWDM1bbkbTK"
   },
   "outputs": [],
   "source": [
    "train_data = TensorDataset(\n",
    "    torch.stack([sample[\"input_ids\"] for sample in wic_train_set]),\n",
    "    torch.stack([sample[\"attention_mask\"] for sample in wic_train_set]),\n",
    "    torch.stack([sample[\"word1_locs\"] for sample in wic_train_set]),\n",
    "    torch.stack([sample[\"word2_locs\"] for sample in wic_train_set]),\n",
    "    torch.stack([sample[\"labels\"] for sample in wic_train_set])\n",
    ")\n",
    "\n",
    "# Create a random sampler and loader\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vp9CqxEGkbTK"
   },
   "source": [
    "## Create Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-24T03:30:57.538826Z",
     "iopub.status.busy": "2023-08-24T03:30:57.537767Z",
     "iopub.status.idle": "2023-08-24T03:30:57.653715Z",
     "shell.execute_reply": "2023-08-24T03:30:57.652934Z",
     "shell.execute_reply.started": "2023-08-24T03:30:57.538826Z"
    },
    "id": "mepC3G1mkbTK",
    "outputId": "7b852f8f-d5be-4d27-824a-6f47b69921c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training sentences: 3,000\n",
      "\n",
      "(3000, 9)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset into a pandas dataframe.\n",
    "df = pd.read_csv(\"hindi-wsd_val.csv\")\n",
    "\n",
    "# Report the number of sentences.\n",
    "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
    "\n",
    "# Display 10 random rows from the data.\n",
    "# df.sample(10)\n",
    "df1 = df\n",
    "print(df1.shape)\n",
    "#Labels - 1 for True and 0 for False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-24T03:30:57.894182Z",
     "iopub.status.busy": "2023-08-24T03:30:57.893820Z",
     "iopub.status.idle": "2023-08-24T03:30:57.901574Z",
     "shell.execute_reply": "2023-08-24T03:30:57.900794Z",
     "shell.execute_reply.started": "2023-08-24T03:30:57.894153Z"
    },
    "id": "YeitzPcHkbTK"
   },
   "outputs": [],
   "source": [
    "sentences_val1= df1.context_instance1.values\n",
    "sentences_val2= df1.context_instance2.values\n",
    "words_val= df1.target_word.values\n",
    "labels_val = df1.labels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-24T03:30:58.253129Z",
     "iopub.status.busy": "2023-08-24T03:30:58.252459Z",
     "iopub.status.idle": "2023-08-24T03:30:58.260399Z",
     "shell.execute_reply": "2023-08-24T03:30:58.258447Z",
     "shell.execute_reply.started": "2023-08-24T03:30:58.253129Z"
    },
    "id": "TA1a_k_PkbTL",
    "outputId": "676ac68b-ea42-4d4b-9f20-06be368ceceb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n"
     ]
    }
   ],
   "source": [
    "print(len(sentences_val1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-24T03:30:58.831148Z",
     "iopub.status.busy": "2023-08-24T03:30:58.830707Z",
     "iopub.status.idle": "2023-08-24T03:31:06.186090Z",
     "shell.execute_reply": "2023-08-24T03:31:06.185416Z",
     "shell.execute_reply.started": "2023-08-24T03:30:58.831118Z"
    },
    "id": "cvmyf0chkbTL",
    "outputId": "253bba5e-7572-46c3-adc3-9e0c847d6752"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2323: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#create validation dataset\n",
    "\n",
    "wic_val_set = create_data_set(sentences_val1,sentences_val2,words_val,labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-24T03:31:06.188153Z",
     "iopub.status.busy": "2023-08-24T03:31:06.187799Z",
     "iopub.status.idle": "2023-08-24T03:31:06.195946Z",
     "shell.execute_reply": "2023-08-24T03:31:06.195066Z",
     "shell.execute_reply.started": "2023-08-24T03:31:06.188121Z"
    },
    "id": "ZRk3wT0rmgM_",
    "outputId": "07ebb8e1-3ee2-4160-a709-2af074d7ef5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2924\n"
     ]
    }
   ],
   "source": [
    "print(len(wic_val_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-24T03:31:06.197474Z",
     "iopub.status.busy": "2023-08-24T03:31:06.197187Z",
     "iopub.status.idle": "2023-08-24T03:31:06.259934Z",
     "shell.execute_reply": "2023-08-24T03:31:06.258872Z",
     "shell.execute_reply.started": "2023-08-24T03:31:06.197446Z"
    },
    "id": "FHhFjsnmkbTL"
   },
   "outputs": [],
   "source": [
    "val_data = TensorDataset(\n",
    "    torch.stack([sample[\"input_ids\"] for sample in wic_val_set]),\n",
    "    torch.stack([sample[\"attention_mask\"] for sample in wic_val_set]),\n",
    "    torch.stack([sample[\"word1_locs\"] for sample in wic_val_set]),\n",
    "    torch.stack([sample[\"word2_locs\"] for sample in wic_val_set]),\n",
    "    torch.stack([sample[\"labels\"] for sample in wic_val_set])\n",
    ")\n",
    "\n",
    "# Create a sampler and loader\n",
    "val_sampler = RandomSampler(val_data)\n",
    "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LcoAG1EskbTL"
   },
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-24T03:31:06.262214Z",
     "iopub.status.busy": "2023-08-24T03:31:06.261853Z",
     "iopub.status.idle": "2023-08-24T03:31:06.272598Z",
     "shell.execute_reply": "2023-08-24T03:31:06.271233Z",
     "shell.execute_reply.started": "2023-08-24T03:31:06.262188Z"
    },
    "id": "GSti34n6kbTL"
   },
   "outputs": [],
   "source": [
    "\n",
    "class WiC_Head(torch.nn.Module):\n",
    "    def __init__(self, model_used,weights,embedding_size=768):\n",
    "        super(WiC_Head, self).__init__()\n",
    "        self.model=model_used\n",
    "        self.embedding_size = embedding_size\n",
    "        self.linear_diff = torch.nn.Linear(embedding_size, 100, bias=True)\n",
    "        self.linear_seperator = torch.nn.Linear(100, 2, bias=True)\n",
    "        self.loss = torch.nn.CrossEntropyLoss(weight=weights)\n",
    "        self.activation = torch.nn.ReLU()\n",
    "        self.softmax = torch.nn.Softmax()\n",
    "\n",
    "        self.to(device)\n",
    "        self.linear_diff.to(device)\n",
    "        self.loss.to(device)\n",
    "        self.linear_seperator.to(device)\n",
    "        self.activation.to(device)\n",
    "        self.softmax.to(device)\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, word1_locs=None, word2_locs=None, labels=None):\n",
    "        batch_size = input_ids.shape[0]\n",
    "        input_ids_tensor = input_ids.to(device)\n",
    "        attention_mask_tensor = attention_mask.to(device)\n",
    "\n",
    "        word1_locs = word1_locs.to(device)\n",
    "        word1_locs=word1_locs.unsqueeze(1)\n",
    "\n",
    "        word2_locs = word2_locs.to(device)\n",
    "        word2_locs=word2_locs.unsqueeze(1)\n",
    "\n",
    "        outputs=model(input_ids_tensor,attention_mask_tensor)\n",
    "\n",
    "        token_embeddings=outputs.hidden_states[-1]\n",
    "        token_embeddings = torch.squeeze(token_embeddings, dim=0)\n",
    "\n",
    "        word1_embs=torch.matmul(word1_locs.float(),token_embeddings.float()).view(batch_size, self.embedding_size)\n",
    "        word2_embs=torch.matmul(word2_locs.float(),token_embeddings.float()).view(batch_size, self.embedding_size)\n",
    "\n",
    "        diff = word1_embs - word2_embs\n",
    "\n",
    "        layer1_results = self.activation(self.linear_diff(diff))\n",
    "        logits = self.softmax(self.linear_seperator(layer1_results))\n",
    "        if labels is not None:\n",
    "            loss = self.loss(logits.view(-1, 2).to(device), labels.view(-1).to(device))\n",
    "            outputs = (loss, logits)\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LeChWR_ukbTU"
   },
   "source": [
    "We need to ensure that both classes are assigned weights accordingly in case any class in our dataset over represented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-24T03:31:06.273849Z",
     "iopub.status.busy": "2023-08-24T03:31:06.273550Z",
     "iopub.status.idle": "2023-08-24T03:31:06.299653Z",
     "shell.execute_reply": "2023-08-24T03:31:06.298449Z",
     "shell.execute_reply.started": "2023-08-24T03:31:06.273822Z"
    },
    "id": "h1pABNHHkbTU",
    "outputId": "6713c128-870d-43c0-9c4f-11a7511cfbf8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99084195 1.00932892]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "#compute the class weights\n",
    "class_wts = compute_class_weight('balanced', classes=[0,1], y=train_labels)\n",
    "\n",
    "print(class_wts)\n",
    "\n",
    "weights= torch.tensor(class_wts,dtype=torch.float)\n",
    "weights = weights.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-24T03:31:06.300933Z",
     "iopub.status.busy": "2023-08-24T03:31:06.300698Z",
     "iopub.status.idle": "2023-08-24T03:31:06.324756Z",
     "shell.execute_reply": "2023-08-24T03:31:06.322419Z",
     "shell.execute_reply.started": "2023-08-24T03:31:06.300903Z"
    },
    "id": "DnMaN73JkbTU",
    "outputId": "198e0146-75f9-4f60-fe68-5b71c4ae0620"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WiC_Head(\n",
       "  (model): XLMRobertaForSequenceClassification(\n",
       "    (roberta): RobertaModel(\n",
       "      (embeddings): RobertaEmbeddings(\n",
       "        (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
       "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "        (token_type_embeddings): Embedding(1, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): RobertaEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (classifier): RobertaClassificationHead(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (linear_diff): Linear(in_features=768, out_features=100, bias=True)\n",
       "  (linear_seperator): Linear(in_features=100, out_features=2, bias=True)\n",
       "  (loss): CrossEntropyLoss()\n",
       "  (activation): ReLU()\n",
       "  (softmax): Softmax(dim=None)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_model = WiC_Head(model, weights,embedding_size = 768)\n",
    "\n",
    "class_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mdyEPZAFkbTV"
   },
   "source": [
    "## Optimization Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Es36dc9bkbTV"
   },
   "source": [
    "I used an improved version of the Adam Optimizer called AdamW for the below reasons:\n",
    "\n",
    "AdamW is an adaptation of the Adam optimizer, designed to incorporate the weight decay (L2 regularization) term directly into the optimization process. The \"W\" in AdamW stands for \"weight decay.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-24T03:31:06.325733Z",
     "iopub.status.busy": "2023-08-24T03:31:06.325733Z",
     "iopub.status.idle": "2023-08-24T03:31:06.334305Z",
     "shell.execute_reply": "2023-08-24T03:31:06.334079Z",
     "shell.execute_reply.started": "2023-08-24T03:31:06.325733Z"
    },
    "id": "9AjVOh69kbTV"
   },
   "outputs": [],
   "source": [
    "\n",
    "param_optimizer = list(class_model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.0}\n",
    "]\n",
    "\n",
    "optimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pfev3Y_rkbTV"
   },
   "source": [
    "## Fine Tune the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-24T03:31:06.336117Z",
     "iopub.status.busy": "2023-08-24T03:31:06.335830Z",
     "iopub.status.idle": "2023-08-24T03:31:06.340855Z",
     "shell.execute_reply": "2023-08-24T03:31:06.339845Z",
     "shell.execute_reply.started": "2023-08-24T03:31:06.336090Z"
    },
    "id": "zATbBnjbkbTW"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-24T03:31:07.872252Z",
     "iopub.status.busy": "2023-08-24T03:31:07.871851Z",
     "iopub.status.idle": "2023-08-24T04:14:03.927913Z",
     "shell.execute_reply": "2023-08-24T04:14:03.925733Z",
     "shell.execute_reply.started": "2023-08-24T03:31:07.872221Z"
    },
    "id": "a2gcgl64kbTW",
    "outputId": "a5ec86ec-9b79-4d8a-ecd0-fd37811a963a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/676167891.py:41: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  logits = self.softmax(self.linear_seperator(layer1_results))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "\tLoss: 0.6934260234946297; Accuracy: 0.49583333333333335\n",
      "Validation:\n",
      "\tLoss=0.6937168357802219; Accuracy: 0.446379781420765\n",
      "Training epoch #2\n",
      "Training:\n",
      "\tLoss: 0.6936487220582508; Accuracy: 0.49776785714285715\n",
      "Validation:\n",
      "\tLoss=0.6936477341287123; Accuracy: 0.4418260473588343\n",
      "Training epoch #3\n",
      "Training:\n",
      "\tLoss: 0.6932335677601043; Accuracy: 0.4928571428571429\n",
      "Validation:\n",
      "\tLoss=0.693821615534402; Accuracy: 0.44193989071038253\n",
      "Training epoch #4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [36], line 56\u001b[0m\n\u001b[1;32m     54\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# get gradient\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m#accelerator.backward(loss)\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# Update model\u001b[39;00m\n\u001b[1;32m     59\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 16 #decreased the size until the CPU stops dying\n",
    "EPOCHS = 10 #could do more for higher accuracy buts takes too long\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels, return_predict_correctness = False):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    if return_predict_correctness:\n",
    "        return np.sum(pred_flat == labels_flat) / len(labels_flat), pred_flat == labels_flat\n",
    "    else:\n",
    "        return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "best_weights = class_model.state_dict()\n",
    "logits_train=[]\n",
    "labels_train=[]\n",
    "logits_test=[]\n",
    "labels_test=[]\n",
    "\n",
    "# maximize from 0\n",
    "max_val_acc = (0, 0)\n",
    "\n",
    "# Store our loss and accuracy for plotting\n",
    "train_loss=[]\n",
    "train_accuracy=[]\n",
    "val_loss=[]\n",
    "val_accuracy=[]\n",
    "epoch_number = 0\n",
    "\n",
    "while epoch_number < EPOCHS:\n",
    "    epoch_number += 1\n",
    "    print(f\"Training epoch #{epoch_number}\")\n",
    "\n",
    "    # Tracking variables\n",
    "    tr_loss, tr_accuracy = 0, 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    # Training\n",
    "    class_model.train()\n",
    "\n",
    "    #class_model.embedder.requires_grad_ = False\n",
    "    # Train the data for each epoch\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        b_input_ids, b_input_mask, b_word1, b_word2, b_labels = batch\n",
    "        #reset gradient\n",
    "        optimizer.zero_grad()\n",
    "        # get input and compute loss\n",
    "        b_input_ids = b_input_ids.to(device)\n",
    "        b_input_mask = b_input_mask.to(device)\n",
    "        b_word1 = b_word1.to(device)\n",
    "        b_word2 = b_word2.to(device)\n",
    "        b_labels=b_labels.to(device)\n",
    "        loss, logits = class_model(input_ids=b_input_ids, attention_mask=b_input_mask, word1_locs = b_word1, word2_locs = b_word2,labels=b_labels)\n",
    "        torch.cuda.empty_cache()\n",
    "        # get gradient\n",
    "        loss.backward()\n",
    "        #accelerator.backward(loss)\n",
    "        # Update model\n",
    "        optimizer.step()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        logits_train.append(logits)\n",
    "        label_ids = b_labels.cpu().numpy()\n",
    "        labels_train.append(label_ids)\n",
    "        # Calculate the accuracy\n",
    "        b_accuracy = flat_accuracy(logits, label_ids) # For RobertaForClassification\n",
    "        # Append to fit history\n",
    "        train_loss.append(loss.item())\n",
    "        train_accuracy.append(b_accuracy)\n",
    "        # Update tracking variables\n",
    "        tr_loss += loss.item()\n",
    "        tr_accuracy += b_accuracy\n",
    "        nb_tr_examples += b_input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "\n",
    "    print(\"Training:\\n\\tLoss: {}; Accuracy: {}\".format(tr_loss/nb_tr_steps, tr_accuracy/nb_tr_steps))\n",
    "\n",
    "    # Validation\n",
    "    class_model.eval()\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in val_dataloader:\n",
    "        b_input_ids, b_input_mask, b_word1, b_word2, b_labels  = batch\n",
    "        # don't store gradients\n",
    "        with torch.no_grad():\n",
    "          # get input and compute loss\n",
    "            loss, logits = class_model(b_input_ids, attention_mask=b_input_mask, word1_locs = b_word1, word2_locs = b_word2,labels=b_labels)\n",
    "            #print(logits)\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        logits_test.append(logits)\n",
    "        label_ids = b_labels.cpu().numpy()\n",
    "        labels_test.append(label_ids)\n",
    "        # Calculate the accuracy\n",
    "        b_accuracy = flat_accuracy(logits, label_ids) # For RobertaForClassification\n",
    "\n",
    "        # Append to fit history\n",
    "        val_loss.append(loss.item())\n",
    "        val_accuracy.append(b_accuracy)\n",
    "        # Update tracking variables\n",
    "        eval_loss += loss.item()\n",
    "        eval_accuracy += b_accuracy\n",
    "        nb_eval_examples += b_input_ids.size(0)\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    eval_acc = eval_accuracy/nb_eval_steps\n",
    "    if eval_acc >= max_val_acc[0]:\n",
    "        max_val_acc = (eval_acc, epoch_number)\n",
    "\n",
    "    print(\"Validation:\\n\\tLoss={}; Accuracy: {}\".format(eval_loss/nb_eval_steps, eval_accuracy/nb_eval_steps))\n",
    "print(f\"Best Validation accuracy ({max_val_acc[0]}) obtained at epoch #{max_val_acc[1]}.\")\n",
    "# Reload the best weights (from memory)\n",
    "class_model.load_state_dict(best_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T05:45:15.060591Z",
     "iopub.status.busy": "2023-08-08T05:45:15.059971Z",
     "iopub.status.idle": "2023-08-08T05:45:17.218113Z",
     "shell.execute_reply": "2023-08-08T05:45:17.217139Z",
     "shell.execute_reply.started": "2023-08-08T05:45:15.060562Z"
    },
    "id": "7CQNl6dvkbTW"
   },
   "outputs": [],
   "source": [
    "PATH = 'saved_weights_xlmr.pt'\n",
    "torch.save(class_model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qPnJo5P7kbTX"
   },
   "source": [
    "## Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-09T01:41:36.483758Z",
     "iopub.status.busy": "2023-08-09T01:41:36.483314Z",
     "iopub.status.idle": "2023-08-09T01:41:36.612081Z",
     "shell.execute_reply": "2023-08-09T01:41:36.610997Z",
     "shell.execute_reply.started": "2023-08-09T01:41:36.483725Z"
    },
    "id": "jxN9fR56kbTX",
    "outputId": "659c4389-297a-4760-b542-14de7c30125d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test sentences: 2,000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the dataset into a pandas dataframe.\n",
    "df = pd.read_csv(\"hindi-wsd_test.csv\")\n",
    "df.head(10)\n",
    "df1=df.sample(2000)\n",
    "\n",
    "# Report the number of sentences.\n",
    "print('Number of test sentences: {:,}\\n'.format(df1.shape[0]))\n",
    "\n",
    "\n",
    "sentences11= list(df1.context_instance1.values)\n",
    "sentences12= list(df1.context_instance2.values)\n",
    "words1= list(df1.target_word.values)\n",
    "labels1 = list(df1.labels.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-09T01:41:40.347879Z",
     "iopub.status.busy": "2023-08-09T01:41:40.346993Z",
     "iopub.status.idle": "2023-08-09T01:41:40.370986Z",
     "shell.execute_reply": "2023-08-09T01:41:40.369874Z",
     "shell.execute_reply.started": "2023-08-09T01:41:40.347851Z"
    },
    "id": "8pjLeIp1kbTX",
    "outputId": "6bb5c09c-fdff-4cd0-db8e-4c9747fa6b5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " इसमें पहली बार बालक के सिर और कलम के बाल उतारे जाते हैं यह कार्य जन्म से एक वर्ष या तीन वर्ष बाद या परिवार की परंपरा के आधार पर और बाद में हो सकता है चरक का विचार है कि केश श्मश्रु एवं नखों के काटने एवं प्रसाधन से पौष्टिकता बल आयुष्य शुचिता और सौंदर्य की प्राप्ति होती है इस संस्कार के पीछे स्वास्थ्य एवं सौंदर्य की भावना ही प्रमुख थी पहले यह घर पर होता था किंतु बाद में देवालयों में # इसलिए साहित्यकार को सरकार के समाजवादी कार्यक्रम में शामिल होने का पूरा हक है मगर सरकार समाजवादी हो तभी अन्यथा नहीं साहित्यकार को यथास्तिथि को तोड़ना है वह इस काम को कलम से तो करेगा ही जुलूस मेंसभा मेंशामिल होकर भीमत व्यक्त करके भी सही को प्रस्तुत करना उसका कर्त्तव्य हो जाता है\n"
     ]
    }
   ],
   "source": [
    "l2=[]\n",
    "for i in range(0,len(sentences1)):\n",
    "    l2.append(sentences1[i]+\"#\"+sentences2[i])\n",
    "    l2.append(sentences2[i]+\"#\"+sentences1[i])\n",
    "print(l2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-09T01:41:42.210091Z",
     "iopub.status.busy": "2023-08-09T01:41:42.209698Z",
     "iopub.status.idle": "2023-08-09T01:41:42.239146Z",
     "shell.execute_reply": "2023-08-09T01:41:42.237778Z",
     "shell.execute_reply.started": "2023-08-09T01:41:42.210063Z"
    },
    "id": "CieyQ0fYkbTY",
    "outputId": "348c4975-e4f0-4e6e-ae0e-c22d36122a48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "102\n",
      "1898\n"
     ]
    }
   ],
   "source": [
    "l1=[]\n",
    "print(len(sentences11))\n",
    "\n",
    "l2=set(l2)\n",
    "for i in range(0,len(sentences11)):\n",
    "    k=sentences12[i]+\"#\"+sentences11[i]\n",
    "    if k in l2:\n",
    "        l1.append(i)\n",
    "print(len(l1))\n",
    "l1.sort(reverse=True)\n",
    "\n",
    "for i in l1:\n",
    "    del sentences11[i]\n",
    "    del sentences12[i]\n",
    "    del words1[i]\n",
    "    del labels1[i]\n",
    "print(len(sentences11))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-09T01:41:50.257687Z",
     "iopub.status.busy": "2023-08-09T01:41:50.256534Z",
     "iopub.status.idle": "2023-08-09T01:41:54.255004Z",
     "shell.execute_reply": "2023-08-09T01:41:54.254036Z",
     "shell.execute_reply.started": "2023-08-09T01:41:50.257638Z"
    },
    "id": "_lFzlp_tkbTY",
    "outputId": "6ebb8f7f-25ed-4162-b53e-3228fea429d1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2393: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1824\n"
     ]
    }
   ],
   "source": [
    "#create test dataset\n",
    "sentences11= np.array(sentences11)\n",
    "sentences12= np.array(sentences12)\n",
    "words1= np.array(words1)\n",
    "labels1 = np.array(labels1)\n",
    "\n",
    "wic_test_set = create_data_set(sentences11,sentences12,words1,labels1)\n",
    "print(len(wic_test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-09T01:41:56.346315Z",
     "iopub.status.busy": "2023-08-09T01:41:56.345913Z",
     "iopub.status.idle": "2023-08-09T01:41:56.374787Z",
     "shell.execute_reply": "2023-08-09T01:41:56.373679Z",
     "shell.execute_reply.started": "2023-08-09T01:41:56.346285Z"
    },
    "id": "B3FUdbI-kbTY"
   },
   "outputs": [],
   "source": [
    "test_data = TensorDataset(\n",
    "    torch.stack([sample[\"input_ids\"] for sample in wic_test_set]),\n",
    "    torch.stack([sample[\"attention_mask\"] for sample in wic_test_set]),\n",
    "    torch.stack([sample[\"word1_locs\"] for sample in wic_test_set]),\n",
    "    torch.stack([sample[\"word2_locs\"] for sample in wic_test_set]),\n",
    "    torch.stack([sample[\"labels\"] for sample in wic_test_set])\n",
    ")\n",
    "\n",
    "# Create a sampler and loader\n",
    "test_sampler = RandomSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-09T01:42:00.577543Z",
     "iopub.status.busy": "2023-08-09T01:42:00.577097Z",
     "iopub.status.idle": "2023-08-09T01:42:03.002724Z",
     "shell.execute_reply": "2023-08-09T01:42:03.001877Z",
     "shell.execute_reply.started": "2023-08-09T01:42:00.577510Z"
    },
    "id": "LvQNEYu-kbTZ",
    "outputId": "f7f20ac3-0907-4f11-929c-be28800da150"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load weights of best model\n",
    "path = 'saved_weights_xlmr.pt'\n",
    "class_model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-09T01:42:03.971875Z",
     "iopub.status.busy": "2023-08-09T01:42:03.971145Z",
     "iopub.status.idle": "2023-08-09T01:43:21.620262Z",
     "shell.execute_reply": "2023-08-09T01:43:21.619358Z",
     "shell.execute_reply.started": "2023-08-09T01:42:03.971847Z"
    },
    "id": "WzXpEoX1kbTZ",
    "outputId": "2dcdafb4-9761-4db2-9e5e-365a7f1d1cac"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-41-09335e4de85a>:60: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  logits = self.softmax(self.linear_seperator(layer1_results))\n"
     ]
    }
   ],
   "source": [
    "# get predictions for test data\n",
    "class_model.eval()\n",
    "total_preds=[]\n",
    "test_labels1=[]\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        batch = [t.to(device) for t in batch]\n",
    "        test_ids, test_mask, test_word1, test_word2, test_labels = batch\n",
    "        _,logits = class_model(test_ids, test_mask, test_word1, test_word2, test_labels)\n",
    "        logits=logits.detach().cpu().numpy()\n",
    "        test_labels1.append(test_labels.detach().cpu().numpy())\n",
    "        #print(logits)\n",
    "        preds = np.argmax(logits, axis=1).flatten()\n",
    "        total_preds.append(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-09T01:43:21.621851Z",
     "iopub.status.busy": "2023-08-09T01:43:21.621577Z",
     "iopub.status.idle": "2023-08-09T01:43:21.629357Z",
     "shell.execute_reply": "2023-08-09T01:43:21.627822Z",
     "shell.execute_reply.started": "2023-08-09T01:43:21.621816Z"
    },
    "id": "9DEc-SSIkbTZ",
    "outputId": "c65b5a7f-1616-434a-8165-529275a6fdfd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1824\n",
      "1824\n"
     ]
    }
   ],
   "source": [
    "total_preds1=[]\n",
    "for i in total_preds:\n",
    "    for i1 in i:\n",
    "        total_preds1.append(i1)\n",
    "\n",
    "print(len(total_preds1))\n",
    "\n",
    "test_labels2=[]\n",
    "for i in test_labels1:\n",
    "    for i1 in i:\n",
    "        test_labels2.append(i1)\n",
    "\n",
    "print(len(test_labels2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-09T01:43:21.630799Z",
     "iopub.status.busy": "2023-08-09T01:43:21.630555Z",
     "iopub.status.idle": "2023-08-09T01:43:21.644691Z",
     "shell.execute_reply": "2023-08-09T01:43:21.643831Z",
     "shell.execute_reply.started": "2023-08-09T01:43:21.630775Z"
    },
    "id": "K3L6lIQekbTa",
    "outputId": "bee63193-38b4-4985-99eb-23807d3b5e40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.94      0.89      1067\n",
      "           1       0.89      0.78      0.83       757\n",
      "\n",
      "    accuracy                           0.87      1824\n",
      "   macro avg       0.87      0.86      0.86      1824\n",
      "weighted avg       0.87      0.87      0.87      1824\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model's performance\n",
    "#preds = np.argmax(preds, axis = 1)\n",
    "print(classification_report(test_labels2, total_preds1))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0195c1e570bc4a50ac6a76398a602f74": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "083979ceec0146fba79b86a788e32c26": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0a48e13d5e2543468a0e7245df6b00a3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0a6bdd7b86a54034ba2cf7b38dcfbafe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1052e793352d457083d5ec3c5986a584": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8a0d3551c04e4d3aac5b5e73920f7c74",
       "IPY_MODEL_704a7ca3dc5d407cbbb85ec79b67bfd0",
       "IPY_MODEL_c3b8572c6f894f5ba8194a15936dd864"
      ],
      "layout": "IPY_MODEL_162bc9a75cce47cab9bb1cc1f78fb46c"
     }
    },
    "14293f95fb4242718956cc9715184120": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "162bc9a75cce47cab9bb1cc1f78fb46c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2e98110b1a9b43c7a8edd80dcd2e4f25": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2f70e3de77cd40c19a5aeda82ebc520f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "329d2bd7f16f4c5280d9b6abd428129b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3417e52af80a46a586683ef0e6c4fbf1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_85370c62279440218d38e8acd255fc05",
       "IPY_MODEL_3d8b6932bf7a44c2a1c00ddcf58906ab",
       "IPY_MODEL_cd0468c7826b46edaa3ab1c3867f6234"
      ],
      "layout": "IPY_MODEL_aaae3d763d89466a952716c22e9fe157"
     }
    },
    "346bcab017db4ff7acd59fc6fa17059e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3a73060d1212478eaf177b22c0069f42": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3d8b6932bf7a44c2a1c00ddcf58906ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8cdfb7f5e335423b8e04f30d125c1020",
      "max": 5069051,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3a73060d1212478eaf177b22c0069f42",
      "value": 5069051
     }
    },
    "464247999a2a4eb2947c9cfcbbcb3bb2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5719f09b75bb48ffbcf0a63f85a3172e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "58edc1b0da10479a865169bb94ce5c2c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5b3aa69346004acf89fc95e55455f834": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b561c3ee2c64492e85a5d8e582c1d8d3",
      "placeholder": "​",
      "style": "IPY_MODEL_464247999a2a4eb2947c9cfcbbcb3bb2",
      "value": "Downloading (…)lve/main/config.json: 100%"
     }
    },
    "5d82cae64a7e47328834ecacaca9bbee": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6d747f4319894c9480932bc234ac7881": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0a6bdd7b86a54034ba2cf7b38dcfbafe",
      "placeholder": "​",
      "style": "IPY_MODEL_9c148419416e4a30a4c28da6e34498a2",
      "value": " 9.10M/9.10M [00:01&lt;00:00, 7.64MB/s]"
     }
    },
    "704a7ca3dc5d407cbbb85ec79b67bfd0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_14293f95fb4242718956cc9715184120",
      "max": 1115567652,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_86194656e8b44b9a82a0530ceb51251b",
      "value": 1115567652
     }
    },
    "745f2c8fd1a54a6cb0dce5e6cd86b0ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7765ee2eec294caab60b7a41b7569920": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "791907143a374b558311e58f958ad6a6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7b0d969ae56948d1b0fc798ad8c2e284": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bc999e1445c2427481877d9bbfc46f5d",
      "placeholder": "​",
      "style": "IPY_MODEL_745f2c8fd1a54a6cb0dce5e6cd86b0ed",
      "value": "Downloading (…)/main/tokenizer.json: 100%"
     }
    },
    "85370c62279440218d38e8acd255fc05": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_58edc1b0da10479a865169bb94ce5c2c",
      "placeholder": "​",
      "style": "IPY_MODEL_8d8bddd9c74d4a05a6892baab0dc7c03",
      "value": "Downloading (…)tencepiece.bpe.model: 100%"
     }
    },
    "86194656e8b44b9a82a0530ceb51251b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8a0d3551c04e4d3aac5b5e73920f7c74": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_346bcab017db4ff7acd59fc6fa17059e",
      "placeholder": "​",
      "style": "IPY_MODEL_a259f3ee14124962ac71a50689e4be52",
      "value": "Downloading model.safetensors: 100%"
     }
    },
    "8cdfb7f5e335423b8e04f30d125c1020": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8d8bddd9c74d4a05a6892baab0dc7c03": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "933dc18174704aec8c63b9c4072bf98e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5b3aa69346004acf89fc95e55455f834",
       "IPY_MODEL_9d07260e677e4837b8b1be3236868f3a",
       "IPY_MODEL_fabb8edac60d42de9615dd695f20b6ca"
      ],
      "layout": "IPY_MODEL_0195c1e570bc4a50ac6a76398a602f74"
     }
    },
    "9c148419416e4a30a4c28da6e34498a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9d07260e677e4837b8b1be3236868f3a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0a48e13d5e2543468a0e7245df6b00a3",
      "max": 615,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5719f09b75bb48ffbcf0a63f85a3172e",
      "value": 615
     }
    },
    "a259f3ee14124962ac71a50689e4be52": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a6f4d19f3c58466da90b6d1f0e22554c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aaae3d763d89466a952716c22e9fe157": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b561c3ee2c64492e85a5d8e582c1d8d3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bc999e1445c2427481877d9bbfc46f5d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c3b8572c6f894f5ba8194a15936dd864": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_791907143a374b558311e58f958ad6a6",
      "placeholder": "​",
      "style": "IPY_MODEL_2f70e3de77cd40c19a5aeda82ebc520f",
      "value": " 1.12G/1.12G [00:02&lt;00:00, 545MB/s]"
     }
    },
    "cd0468c7826b46edaa3ab1c3867f6234": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_329d2bd7f16f4c5280d9b6abd428129b",
      "placeholder": "​",
      "style": "IPY_MODEL_a6f4d19f3c58466da90b6d1f0e22554c",
      "value": " 5.07M/5.07M [00:01&lt;00:00, 3.45MB/s]"
     }
    },
    "ef0d749846764aeab947cad9ab2c018a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5d82cae64a7e47328834ecacaca9bbee",
      "max": 9096718,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_083979ceec0146fba79b86a788e32c26",
      "value": 9096718
     }
    },
    "fabb8edac60d42de9615dd695f20b6ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2e98110b1a9b43c7a8edd80dcd2e4f25",
      "placeholder": "​",
      "style": "IPY_MODEL_fe4e419805e547b28863c46c92e0ba7a",
      "value": " 615/615 [00:00&lt;00:00, 52.5kB/s]"
     }
    },
    "fcd03a1f863c42fd82963fc7f063ac14": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7b0d969ae56948d1b0fc798ad8c2e284",
       "IPY_MODEL_ef0d749846764aeab947cad9ab2c018a",
       "IPY_MODEL_6d747f4319894c9480932bc234ac7881"
      ],
      "layout": "IPY_MODEL_7765ee2eec294caab60b7a41b7569920"
     }
    },
    "fe4e419805e547b28863c46c92e0ba7a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
